{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auto-sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author's description:\n",
    "\n",
    "auto-sklearn is an automated machine learning toolkit and a drop-in replacement for a scikit-learn estimator\n",
    "\n",
    "#### Useful links:\n",
    "\n",
    "[install link](https://automl.github.io/auto-sklearn/master/installation.html),\n",
    "[git](https://github.com/automl/auto-sklearn),\n",
    "[manual](https://automl.github.io/auto-sklearn/master/manual.html),\n",
    "[parallel instances](https://automl.github.io/auto-sklearn/master/examples/example_parallel_manual_spawning.html),\n",
    "[parallel runs on one machine](https://automl.github.io/auto-sklearn/master/examples/example_parallel_n_jobs.html),\n",
    "[cross validation](https://automl.github.io/auto-sklearn/master/examples/example_crossvalidation.html),\n",
    "[feature types](https://automl.github.io/auto-sklearn/master/examples/example_feature_types.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auto-sklearn builds ensembles, provides good control of the auto-ML run details, and makes exporting easy due to its scikit-learn foundations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting auto-sklearn==0.6.0\n",
      "  Downloading auto-sklearn-0.6.0.tar.gz (3.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9 MB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from auto-sklearn==0.6.0) (46.1.3.post20200330)\n",
      "Requirement already satisfied: nose in /opt/conda/lib/python3.6/site-packages (from auto-sklearn==0.6.0) (1.3.7)\n",
      "Requirement already satisfied: Cython in /opt/conda/lib/python3.6/site-packages (from auto-sklearn==0.6.0) (0.29.15)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from auto-sklearn==0.6.0) (1.18.2)\n",
      "Requirement already satisfied: scipy>=0.14.1 in /opt/conda/lib/python3.6/site-packages (from auto-sklearn==0.6.0) (1.4.1)\n",
      "Collecting scikit-learn<0.22,>=0.21.0\n",
      "  Downloading scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7 MB 45.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lockfile\n",
      "  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from auto-sklearn==0.6.0) (0.14.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.6/site-packages (from auto-sklearn==0.6.0) (5.7.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from auto-sklearn==0.6.0) (3.13)\n",
      "Collecting liac-arff\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from auto-sklearn==0.6.0) (0.25.3)\n",
      "Collecting ConfigSpace<0.5,>=0.4.0\n",
      "  Downloading ConfigSpace-0.4.19-cp36-cp36m-manylinux2014_x86_64.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 95.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pynisher>=0.4.2\n",
      "  Downloading pynisher-0.6.4.tar.gz (11 kB)\n",
      "Collecting pyrfr<0.9,>=0.7\n",
      "  Downloading pyrfr-0.8.2-cp36-cp36m-manylinux2014_x86_64.whl (3.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9 MB 81.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smac==0.8\n",
      "  Downloading smac-0.8.0.tar.gz (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from pandas->auto-sklearn==0.6.0) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->auto-sklearn==0.6.0) (2018.9)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.6/site-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn==0.6.0) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from smac==0.8->auto-sklearn==0.6.0) (1.14.0)\n",
      "Collecting typing\n",
      "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 16.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sphinx in /opt/conda/lib/python3.6/site-packages (from smac==0.8->auto-sklearn==0.6.0) (1.8.5)\n",
      "Collecting sphinx_rtd_theme\n",
      "  Downloading sphinx_rtd_theme-1.0.0-py2.py3-none-any.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 68.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: docutils>=0.11 in /opt/conda/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn==0.6.0) (0.16)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /opt/conda/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn==0.6.0) (0.7.12)\n",
      "Requirement already satisfied: imagesize in /opt/conda/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn==0.6.0) (1.2.0)\n",
      "Requirement already satisfied: Pygments>=2.0 in /opt/conda/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn==0.6.0) (2.6.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn==0.6.0) (17.1)\n",
      "Requirement already satisfied: Jinja2>=2.3 in /opt/conda/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn==0.6.0) (2.11.2)\n",
      "Requirement already satisfied: sphinxcontrib-websupport in /opt/conda/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn==0.6.0) (1.2.0)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /opt/conda/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn==0.6.0) (2.8.0)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /opt/conda/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn==0.6.0) (1.9.1)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from sphinx->smac==0.8->auto-sklearn==0.6.0) (2.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=2.3->sphinx->smac==0.8->auto-sklearn==0.6.0) (1.1.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn==0.6.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn==0.6.0) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn==0.6.0) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn==0.6.0) (2020.4.5.1)\n",
      "Building wheels for collected packages: auto-sklearn, liac-arff, pynisher, smac, typing\n",
      "  Building wheel for auto-sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for auto-sklearn: filename=auto_sklearn-0.6.0-cp36-cp36m-linux_x86_64.whl size=4268818 sha256=19c2dd4ba090540906353e7ea703936021df819289b5cbb8d4cf15bb3099c7c0\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/1b/9a/78/0dd70afe14ccb1f8d3fb51cedda41b52c4cfc398eeb3efeb60\n",
      "  Building wheel for liac-arff (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=d29b00d32c24aa2afbf7fe010f74935feb8577b044e0704a4e9a4e1796a73943\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/53/ba/da/8562a6a6dbb428fd1ecc21053106df3948645cd991958f669b\n",
      "  Building wheel for pynisher (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pynisher: filename=pynisher-0.6.4-py3-none-any.whl size=7043 sha256=967e54c39e8b2b2120e80b11cb0a50fad2e47cca1a1ec8c84ec44153b403ad3b\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/69/e4/a2/9835f7589fd514dd4e1628e254c2f739036d864897892ffc89\n",
      "  Building wheel for smac (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smac: filename=smac-0.8.0-py3-none-any.whl size=97294 sha256=7c37694ad823a2e1eceea9371a4f4455b55690aa9700871221228a8521426118\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/42/ee/59/abe62fe4587382aefde4f342badba96a31b70b8c0091263683\n",
      "  Building wheel for typing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26308 sha256=3d97e80c52d4bb6aa30b5e40223dd18597e838aa5430baf76fb93f9c979ef908\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/5f/63/c2/b85489bbea28cb5d36cfe197244f898428004fa3caa7a23116\n",
      "Successfully built auto-sklearn liac-arff pynisher smac typing\n",
      "Installing collected packages: scikit-learn, lockfile, liac-arff, ConfigSpace, pynisher, pyrfr, typing, sphinx-rtd-theme, smac, auto-sklearn\n",
      "Successfully installed ConfigSpace-0.4.19 auto-sklearn-0.6.0 liac-arff-2.5.0 lockfile-0.12.2 pynisher-0.6.4 pyrfr-0.8.2 scikit-learn-0.21.3 smac-0.8.0 sphinx-rtd-theme-1.0.0 typing-3.7.4.3\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install auto-sklearn==0.6.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the latest verified version of autosklearn in this notebook was 0.5.2\n",
    "autosklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there can be a lot of warnings in auto-sklearn\n",
    "#especially if you overwrite existing files\n",
    "#turning off for demo purposes\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the classification function\n",
    "\n",
    "auto-sklearn is mostly a wrapper around scikit-learn. It was not the intention of the authors to allow user control over details such as the modeling algorithm and typical hyper-parameter choices. Control is several layers deep in the [SMAC](https://automl.github.io/SMAC3/master/) space and scenario settings. The user can control the time is takes to build the ensemble, the resampling strategy and the parallelization of the work across CPUs on the machine. These will be demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mautosklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoSklearnClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtime_left_for_this_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mper_run_time_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minitial_configurations_via_metalearning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mensemble_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mensemble_nbest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mensemble_memory_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mml_memory_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3072\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minclude_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexclude_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minclude_preprocessors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexclude_preprocessors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'holdout'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresampling_strategy_arguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtmp_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelete_tmp_folder_after_terminate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelete_output_folder_after_terminate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshared_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdisable_evaluator_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mget_smac_object_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msmac_scenario_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogging_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetadata_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      This class implements the classification task.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Parameters\n",
       "----------\n",
       "time_left_for_this_task : int, optional (default=3600)\n",
       "    Time limit in seconds for the search of appropriate\n",
       "    models. By increasing this value, *auto-sklearn* has a higher\n",
       "    chance of finding better models.\n",
       "\n",
       "per_run_time_limit : int, optional (default=360)\n",
       "    Time limit for a single call to the machine learning model.\n",
       "    Model fitting will be terminated if the machine learning\n",
       "    algorithm runs over the time limit. Set this value high enough so\n",
       "    that typical machine learning algorithms can be fit on the\n",
       "    training data.\n",
       "\n",
       "initial_configurations_via_metalearning : int, optional (default=25)\n",
       "    Initialize the hyperparameter optimization algorithm with this\n",
       "    many configurations which worked well on previously seen\n",
       "    datasets. Disable if the hyperparameter optimization algorithm\n",
       "    should start from scratch.\n",
       "\n",
       "ensemble_size : int, optional (default=50)\n",
       "    Number of models added to the ensemble built by *Ensemble\n",
       "    selection from libraries of models*. Models are drawn with\n",
       "    replacement.\n",
       "\n",
       "ensemble_nbest : int, optional (default=50)\n",
       "    Only consider the ``ensemble_nbest`` models when building an\n",
       "    ensemble. Implements `Model Library Pruning` from `Getting the\n",
       "    most out of ensemble selection`.\n",
       "\n",
       "ensemble_memory_limit : int, optional (1024)\n",
       "    Memory limit in MB for the ensemble building process.\n",
       "    `auto-sklearn` will reduce the number of considered models\n",
       "    (``ensemble_nbest``) if the memory limit is reached.\n",
       "\n",
       "seed : int, optional (default=1)\n",
       "    Used to seed SMAC. Will determine the output file names.\n",
       "\n",
       "ml_memory_limit : int, optional (3072)\n",
       "    Memory limit in MB for the machine learning algorithm.\n",
       "    `auto-sklearn` will stop fitting the machine learning algorithm if\n",
       "    it tries to allocate more than `ml_memory_limit` MB.\n",
       "\n",
       "include_estimators : list, optional (None)\n",
       "    If None, all possible estimators are used. Otherwise specifies\n",
       "    set of estimators to use.\n",
       "\n",
       "exclude_estimators : list, optional (None)\n",
       "    If None, all possible estimators are used. Otherwise specifies\n",
       "    set of estimators not to use. Incompatible with include_estimators.\n",
       "\n",
       "include_preprocessors : list, optional (None)\n",
       "    If None all possible preprocessors are used. Otherwise specifies set\n",
       "    of preprocessors to use.\n",
       "\n",
       "exclude_preprocessors : list, optional (None)\n",
       "    If None all possible preprocessors are used. Otherwise specifies set\n",
       "    of preprocessors not to use. Incompatible with\n",
       "    include_preprocessors.\n",
       "\n",
       "resampling_strategy : string or object, optional ('holdout')\n",
       "    how to to handle overfitting, might need 'resampling_strategy_arguments'\n",
       "\n",
       "    * 'holdout': 67:33 (train:test) split\n",
       "    * 'holdout-iterative-fit':  67:33 (train:test) split, calls iterative\n",
       "      fit where possible\n",
       "    * 'cv': crossvalidation, requires 'folds'\n",
       "    * 'partial-cv': crossvalidation with intensification, requires\n",
       "      'folds'\n",
       "    * BaseCrossValidator object: any BaseCrossValidator class found\n",
       "                                in scikit-learn model_selection module\n",
       "    * _RepeatedSplits object: any _RepeatedSplits class found\n",
       "                              in scikit-learn model_selection module\n",
       "    * BaseShuffleSplit object: any BaseShuffleSplit class found\n",
       "                              in scikit-learn model_selection module\n",
       "\n",
       "resampling_strategy_arguments : dict, optional if 'holdout' (train_size default=0.67)\n",
       "    Additional arguments for resampling_strategy:\n",
       "\n",
       "    * ``train_size`` should be between 0.0 and 1.0 and represent the\n",
       "      proportion of the dataset to include in the train split.\n",
       "    * ``shuffle`` determines whether the data is shuffled prior to\n",
       "      splitting it into train and validation.\n",
       "\n",
       "    Available arguments:\n",
       "\n",
       "    * 'holdout': {'train_size': float}\n",
       "    * 'holdout-iterative-fit':  {'train_size': float}\n",
       "    * 'cv': {'folds': int}\n",
       "    * 'partial-cv': {'folds': int, 'shuffle': bool}\n",
       "    * BaseCrossValidator or _RepeatedSplits or BaseShuffleSplit object: all arguments\n",
       "        required by chosen class as specified in scikit-learn documentation.\n",
       "        If arguments are not provided, scikit-learn defaults are used.\n",
       "        If no defaults are available, an exception is raised.\n",
       "        Refer to the 'n_splits' argument as 'folds'.\n",
       "\n",
       "tmp_folder : string, optional (None)\n",
       "    folder to store configuration output and log files, if ``None``\n",
       "    automatically use ``/tmp/autosklearn_tmp_$pid_$random_number``\n",
       "\n",
       "output_folder : string, optional (None)\n",
       "    folder to store predictions for optional test set, if ``None``\n",
       "    automatically use ``/tmp/autosklearn_output_$pid_$random_number``\n",
       "\n",
       "delete_tmp_folder_after_terminate: string, optional (True)\n",
       "    remove tmp_folder, when finished. If tmp_folder is None\n",
       "    tmp_dir will always be deleted\n",
       "\n",
       "delete_output_folder_after_terminate: bool, optional (True)\n",
       "    remove output_folder, when finished. If output_folder is None\n",
       "    output_dir will always be deleted\n",
       "\n",
       "shared_mode : bool, optional (False)\n",
       "    Run smac in shared-model-node. This only works if arguments\n",
       "    ``tmp_folder`` and ``output_folder`` are given and both\n",
       "    ``delete_tmp_folder_after_terminate`` and\n",
       "    ``delete_output_folder_after_terminate`` are set to False. Cannot\n",
       "    be used together with ``n_jobs``.\n",
       "\n",
       "n_jobs : int, optional, experimental\n",
       "    The number of jobs to run in parallel for ``fit()``. Cannot be\n",
       "    used together with ``shared_mode``. ``-1`` means using all\n",
       "    processors. By default, Auto-sklearn uses a single core for\n",
       "    fitting the machine learning model and a single core for fitting\n",
       "    an ensemble. Ensemble building is not affected by ``n_jobs`` but\n",
       "    can be controlled by the number of models in the ensemble. In\n",
       "    contrast to most scikit-learn models, ``n_jobs`` given in the\n",
       "    constructor is not applied to the ``predict()`` method.\n",
       "\n",
       "disable_evaluator_output: bool or list, optional (False)\n",
       "    If True, disable model and prediction output. Cannot be used\n",
       "    together with ensemble building. ``predict()`` cannot be used when\n",
       "    setting this True. Can also be used as a list to pass more\n",
       "    fine-grained information on what to save. Allowed elements in the\n",
       "    list are:\n",
       "\n",
       "    * ``'y_optimization'`` : do not save the predictions for the\n",
       "      optimization/validation set, which would later on be used to build\n",
       "      an ensemble.\n",
       "    * ``'model'`` : do not save any model files\n",
       "\n",
       "smac_scenario_args : dict, optional (None)\n",
       "    Additional arguments inserted into the scenario of SMAC. See the\n",
       "    `SMAC documentation <https://automl.github.io/SMAC3/stable/options.html?highlight=scenario#scenario>`_\n",
       "    for a list of available arguments.\n",
       "\n",
       "get_smac_object_callback : callable\n",
       "    Callback function to create an object of class\n",
       "    `smac.optimizer.smbo.SMBO <https://automl.github.io/SMAC3/stable/apidoc/smac.optimizer.smbo.html>`_.\n",
       "    The function must accept the arguments ``scenario_dict``,\n",
       "    ``instances``, ``num_params``, ``runhistory``, ``seed`` and ``ta``.\n",
       "    This is an advanced feature. Use only if you are familiar with\n",
       "    `SMAC <https://automl.github.io/SMAC3/stable/index.html>`_.\n",
       "\n",
       "logging_config : dict, optional (None)\n",
       "    dictionary object specifying the logger configuration. If None,\n",
       "    the default logging.yaml file is used, which can be found in\n",
       "    the directory ``util/logging.yaml`` relative to the installation.\n",
       "\n",
       "metadata_directory : str, optional (None)\n",
       "    path to the metadata directory. If None, the default directory\n",
       "    (autosklearn.metalearning.files) is used.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "\n",
       "cv_results\\_ : dict of numpy (masked) ndarrays\n",
       "    A dict with keys as column headers and values as columns, that can be\n",
       "    imported into a pandas ``DataFrame``.\n",
       "\n",
       "    Not all keys returned by scikit-learn are supported yet.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.6/site-packages/autosklearn/estimators.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?autosklearn.classification.AutoSklearnClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the heart disease dataset\n",
    "\n",
    "Note that in this cell we are calling **sklearn.model_selection.train_test_split()** twice and creating two sets of heart disease (hd) data for model fitting and testing. One is for the hd data without one hot encoding (ohe) and the other has the ohe columns. \n",
    "\n",
    "auto-sklearn accepts a list of categorical features and has several methods for treating categorical data. In this notebook we try both approaches - building ohe columns ourselves and letting auto-sklearn do its thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "/mnt/data/raw/heart.csv\n",
    "\n",
    "attribute documentation:\n",
    "      age: age in years\n",
    "      sex: sex (1 = male; 0 = female)\n",
    "      cp: chest pain type\n",
    "        -- Value 1: typical angina\n",
    "        -- Value 2: atypical angina\n",
    "        -- Value 3: non-anginal pain\n",
    "        -- Value 4: asymptomatic\n",
    "     trestbps: resting blood pressure (in mm Hg on admission to the \n",
    "        hospital)\n",
    "     chol: serum cholestoral in mg/dl\n",
    "     fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "     restecg: resting electrocardiographic results\n",
    "        -- Value 0: normal\n",
    "        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \n",
    "                    elevation or depression of > 0.05 mV)\n",
    "        -- Value 2: showing probable or definite left ventricular hypertrophy\n",
    "                    by Estes' criteria\n",
    "     thalach: maximum heart rate achieved\n",
    "     exang: exercise induced angina (1 = yes; 0 = no)\n",
    "     oldpeak = ST depression induced by exercise relative to rest\n",
    "     slope: the slope of the peak exercise ST segment\n",
    "        -- Value 1: upsloping\n",
    "        -- Value 2: flat\n",
    "        -- Value 3: downsloping\n",
    "     ca: number of major vessels (0-3) colored by flourosopy\n",
    "     thal: \n",
    "         3 = normal; \n",
    "         6 = fixed defect; \n",
    "         7 = reversable defect\n",
    "     target: diagnosis of heart disease (angiographic disease status)\n",
    "        -- Value 0: < 50% diameter narrowing\n",
    "        -- Value 1: > 50% diameter narrowing\n",
    " '''\n",
    "\n",
    "#load and clean the data----------------------\n",
    "\n",
    "#column names\n",
    "names = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang', \\\n",
    "         'oldpeak','slope','ca','thal','target']\n",
    "\n",
    "#load data from Domino project directory\n",
    "hd_data = pd.read_csv(\"../data/raw/heart.csv\", header=None, names=names)\n",
    "\n",
    "#in case some data comes in as string\n",
    "#convert to numeric and coerce errors to NaN\n",
    "for col in hd_data.columns:  # Iterate over chosen columns\n",
    "    hd_data[col] = pd.to_numeric(hd_data[col], errors='coerce')\n",
    "    \n",
    "#drop nulls\n",
    "hd_data.dropna(inplace=True)\n",
    "\n",
    "#non-ohe data---------------------------------\n",
    "   \n",
    "#load the X and y set as a numpy array\n",
    "X_hd = hd_data.drop('target', axis=1).values\n",
    "y_hd = hd_data['target'].values\n",
    "\n",
    "#build the train and test sets\n",
    "X_hd_train, X_hd_test, y_hd_train, y_hd_test = \\\n",
    "    sklearn.model_selection.train_test_split(X_hd, y_hd, random_state=12)\n",
    "\n",
    "#now do ohe-----------------------------------\n",
    "\n",
    "#function to do one hot encoding for categorical columns\n",
    "def create_dummies(data, cols, drop1st=True):\n",
    "    for c in cols:\n",
    "        dummies_df = pd.get_dummies(data[c], prefix=c, drop_first=drop1st)  \n",
    "        data=pd.concat([data, dummies_df], axis=1)\n",
    "        data = data.drop([c], axis=1)\n",
    "    return data\n",
    "\n",
    "cat_cols = ['cp', 'restecg', 'slope', 'ca', 'thal']\n",
    "hd_data = create_dummies(hd_data, cat_cols)\n",
    "    \n",
    "#load the X and y set as a numpy array\n",
    "X_hd_ohe = hd_data.drop('target', axis=1).values\n",
    "y_hd_ohe = hd_data['target'].values\n",
    "\n",
    "#build the train and test sets\n",
    "X_hd_ohe_train, X_hd_ohe_test, y_hd_ohe_train, y_hd_ohe_test = \\\n",
    "    sklearn.model_selection.train_test_split(X_hd_ohe, y_hd_ohe, \\\n",
    "                                             random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to delete the output and temp directories of auto-sklearn\n",
    "\n",
    "You'll need to clear the previous folders to avoid overwrite errors. Alternatively, you can create new output directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(directories_, delete_):\n",
    "    for d in directories_:\n",
    "        if delete_:\n",
    "            print('deleting', d)\n",
    "            completed = subprocess.run(\n",
    "                ['rm', '-rf', d],\n",
    "                stdout=subprocess.PIPE,\n",
    "            )\n",
    "            print(completed.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a model on ohe data with holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting ../results/tmp_hd_holdout\n",
      "\n",
      "deleting ../results/out_hd_holdout\n",
      "\n",
      "[WARNING] [2021-12-02 19:18:43,308:EnsembleBuilder(1):heart_disease] No models better than random - using Dummy Score!\n",
      "[WARNING] [2021-12-02 19:18:43,315:EnsembleBuilder(1):heart_disease] No models better than random - using Dummy Score!\n",
      "CPU times: user 21.8 s, sys: 567 ms, total: 22.3 s\n",
      "Wall time: 55.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#set and clear the output directories\n",
    "directories = ['../results/tmp_hd_holdout', \\\n",
    "               '../results/out_hd_holdout']\n",
    "cleanup(directories, True)\n",
    "\n",
    "#build the auto-sklearn routine\n",
    "automl_hd_ohe = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=60,\n",
    "    per_run_time_limit=30,\n",
    "    tmp_folder=directories[0],\n",
    "    output_folder=directories[1],\n",
    "    disable_evaluator_output=False,\n",
    "    resampling_strategy='holdout',\n",
    "    resampling_strategy_arguments={'train_size': 0.67}\n",
    ")\n",
    "\n",
    "#call it\n",
    "automl_hd_ohe.fit(X_hd_ohe_train, y_hd_ohe_train, \\\n",
    "                  dataset_name='heart_disease')\n",
    "\n",
    "#save the predicitons\n",
    "predictions_hd_ohe = automl_hd_ohe.predict(X_hd_ohe_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting with autosklearn\n",
    "\n",
    "A common mistake is to call **fit_ensemble()** after already running **fit()**. **fit()** both optimizes the machine learning models and builds an ensemble out of them. To disable ensembling when running **fit()** (with parallel instances for example) set ensemble_size to 0. Then **fit_ensemble()** would be needed once all models have been built.\n",
    "\n",
    "To save fitted models, use typical [pickle procedures](https://scikit-learn.org/stable/modules/model_persistence.html#persistence-example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "\n",
    "Accuracy, sprint stats, and model details are available. \n",
    "\n",
    "Later we will run auto-sklearn in parallel. Note the number of models built here and compare it to the number built with parallelization turned on. \n",
    "\n",
    "The model details give you insight into what auto-sklearn is doing under the hood. You can see the modeling algorithm used and all the parameter settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.75\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Sprint Stats:\n",
      "auto-sklearn results:\n",
      "  Dataset name: heart_disease\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.893333\n",
      "  Number of target algorithm runs: 72\n",
      "  Number of successful target algorithm runs: 68\n",
      "  Number of crashed target algorithm runs: 4\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Model Details:\n",
      "[(0.140000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'sgd', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'extra_trees_preproc_for_classification', 'rescaling:__choice__': 'none', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:sgd:alpha': 0.0008259251558823811, 'classifier:sgd:average': 'True', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'constant', 'classifier:sgd:loss': 'perceptron', 'classifier:sgd:penalty': 'l1', 'classifier:sgd:tol': 0.0053724305488662225, 'preprocessor:extra_trees_preproc_for_classification:bootstrap': 'False', 'preprocessor:extra_trees_preproc_for_classification:criterion': 'gini', 'preprocessor:extra_trees_preproc_for_classification:max_depth': 'None', 'preprocessor:extra_trees_preproc_for_classification:max_features': 0.21710505927563428, 'preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes': 'None', 'preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease': 0.0, 'preprocessor:extra_trees_preproc_for_classification:min_samples_leaf': 4, 'preprocessor:extra_trees_preproc_for_classification:min_samples_split': 13, 'preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf': 0.0, 'preprocessor:extra_trees_preproc_for_classification:n_estimators': 100, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.0014184150255170226, 'classifier:sgd:eta0': 1.7369869126795405e-07},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.120000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'sgd', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'nystroem_sampler', 'rescaling:__choice__': 'minmax', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False', 'classifier:sgd:alpha': 5.6261158385241367e-05, 'classifier:sgd:average': 'True', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'constant', 'classifier:sgd:loss': 'perceptron', 'classifier:sgd:penalty': 'l2', 'classifier:sgd:tol': 0.00010235984698480301, 'preprocessor:nystroem_sampler:kernel': 'poly', 'preprocessor:nystroem_sampler:n_components': 67, 'classifier:sgd:eta0': 1.051932200415674e-05, 'preprocessor:nystroem_sampler:coef0': -0.5748850260339962, 'preprocessor:nystroem_sampler:degree': 2, 'preprocessor:nystroem_sampler:gamma': 1.0340462502787229},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.100000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'sgd', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'feature_agglomeration', 'rescaling:__choice__': 'minmax', 'classifier:sgd:alpha': 0.009022254926837012, 'classifier:sgd:average': 'True', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'invscaling', 'classifier:sgd:loss': 'hinge', 'classifier:sgd:penalty': 'l2', 'classifier:sgd:tol': 0.000108760141552381, 'preprocessor:feature_agglomeration:affinity': 'manhattan', 'preprocessor:feature_agglomeration:linkage': 'complete', 'preprocessor:feature_agglomeration:n_clusters': 107, 'preprocessor:feature_agglomeration:pooling_func': 'mean', 'classifier:sgd:eta0': 1.05458028914072e-07, 'classifier:sgd:power_t': 0.6700967811625143},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.100000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'sgd', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'nystroem_sampler', 'rescaling:__choice__': 'minmax', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False', 'classifier:sgd:alpha': 5.6261158385241367e-05, 'classifier:sgd:average': 'True', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'constant', 'classifier:sgd:loss': 'perceptron', 'classifier:sgd:penalty': 'elasticnet', 'classifier:sgd:tol': 0.00010235984698480301, 'preprocessor:nystroem_sampler:kernel': 'poly', 'preprocessor:nystroem_sampler:n_components': 67, 'classifier:sgd:eta0': 1.051932200415674e-05, 'classifier:sgd:l1_ratio': 3.0712276747159755e-08, 'preprocessor:nystroem_sampler:coef0': -0.5748850260339962, 'preprocessor:nystroem_sampler:degree': 2, 'preprocessor:nystroem_sampler:gamma': 1.0340462502787229},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.080000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'liblinear_svc', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'select_rates', 'rescaling:__choice__': 'standardize', 'classifier:liblinear_svc:C': 0.9361439952008628, 'classifier:liblinear_svc:dual': 'False', 'classifier:liblinear_svc:fit_intercept': 'True', 'classifier:liblinear_svc:intercept_scaling': 1, 'classifier:liblinear_svc:loss': 'squared_hinge', 'classifier:liblinear_svc:multi_class': 'ovr', 'classifier:liblinear_svc:penalty': 'l2', 'classifier:liblinear_svc:tol': 0.011270619668728919, 'preprocessor:select_rates:alpha': 0.4383722347883825, 'preprocessor:select_rates:mode': 'fdr', 'preprocessor:select_rates:score_func': 'chi2'},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.060000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'liblinear_svc', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'feature_agglomeration', 'rescaling:__choice__': 'none', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:liblinear_svc:C': 0.22780164772427516, 'classifier:liblinear_svc:dual': 'False', 'classifier:liblinear_svc:fit_intercept': 'True', 'classifier:liblinear_svc:intercept_scaling': 1, 'classifier:liblinear_svc:loss': 'squared_hinge', 'classifier:liblinear_svc:multi_class': 'ovr', 'classifier:liblinear_svc:penalty': 'l2', 'classifier:liblinear_svc:tol': 2.1090456444647642e-05, 'preprocessor:feature_agglomeration:affinity': 'cosine', 'preprocessor:feature_agglomeration:linkage': 'average', 'preprocessor:feature_agglomeration:n_clusters': 221, 'preprocessor:feature_agglomeration:pooling_func': 'mean', 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.14772889925151694},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.060000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'lda', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'liblinear_svc_preprocessor', 'rescaling:__choice__': 'normalize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False', 'classifier:lda:n_components': 141, 'classifier:lda:shrinkage': 'None', 'classifier:lda:tol': 0.048894869863846224, 'preprocessor:liblinear_svc_preprocessor:C': 451.0275132494355, 'preprocessor:liblinear_svc_preprocessor:dual': 'False', 'preprocessor:liblinear_svc_preprocessor:fit_intercept': 'True', 'preprocessor:liblinear_svc_preprocessor:intercept_scaling': 1, 'preprocessor:liblinear_svc_preprocessor:loss': 'squared_hinge', 'preprocessor:liblinear_svc_preprocessor:multi_class': 'ovr', 'preprocessor:liblinear_svc_preprocessor:penalty': 'l1', 'preprocessor:liblinear_svc_preprocessor:tol': 0.0001454153817164754},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.060000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'k_nearest_neighbors', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'feature_agglomeration', 'rescaling:__choice__': 'minmax', 'classifier:k_nearest_neighbors:n_neighbors': 2, 'classifier:k_nearest_neighbors:p': 1, 'classifier:k_nearest_neighbors:weights': 'distance', 'preprocessor:feature_agglomeration:affinity': 'manhattan', 'preprocessor:feature_agglomeration:linkage': 'average', 'preprocessor:feature_agglomeration:n_clusters': 76, 'preprocessor:feature_agglomeration:pooling_func': 'max'},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.040000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'liblinear_svc', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'select_rates', 'rescaling:__choice__': 'standardize', 'classifier:liblinear_svc:C': 1.0, 'classifier:liblinear_svc:dual': 'False', 'classifier:liblinear_svc:fit_intercept': 'True', 'classifier:liblinear_svc:intercept_scaling': 1, 'classifier:liblinear_svc:loss': 'squared_hinge', 'classifier:liblinear_svc:multi_class': 'ovr', 'classifier:liblinear_svc:penalty': 'l2', 'classifier:liblinear_svc:tol': 0.00010000000000000009, 'preprocessor:select_rates:alpha': 0.24774639145888958, 'preprocessor:select_rates:mode': 'fdr', 'preprocessor:select_rates:score_func': 'chi2'},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.040000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'libsvm_svc', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'liblinear_svc_preprocessor', 'rescaling:__choice__': 'none', 'classifier:libsvm_svc:C': 2362.7930346050302, 'classifier:libsvm_svc:gamma': 0.6488051937070094, 'classifier:libsvm_svc:kernel': 'poly', 'classifier:libsvm_svc:max_iter': -1, 'classifier:libsvm_svc:shrinking': 'False', 'classifier:libsvm_svc:tol': 0.00018138703132454436, 'preprocessor:liblinear_svc_preprocessor:C': 13980.91178256001, 'preprocessor:liblinear_svc_preprocessor:dual': 'False', 'preprocessor:liblinear_svc_preprocessor:fit_intercept': 'True', 'preprocessor:liblinear_svc_preprocessor:intercept_scaling': 1, 'preprocessor:liblinear_svc_preprocessor:loss': 'squared_hinge', 'preprocessor:liblinear_svc_preprocessor:multi_class': 'ovr', 'preprocessor:liblinear_svc_preprocessor:penalty': 'l1', 'preprocessor:liblinear_svc_preprocessor:tol': 0.0023061197818249283, 'classifier:libsvm_svc:coef0': 0.7828919129195908, 'classifier:libsvm_svc:degree': 2},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.040000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'libsvm_svc', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'polynomial', 'rescaling:__choice__': 'quantile_transformer', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False', 'classifier:libsvm_svc:C': 1625.4459953715962, 'classifier:libsvm_svc:gamma': 0.001697493768524769, 'classifier:libsvm_svc:kernel': 'poly', 'classifier:libsvm_svc:max_iter': -1, 'classifier:libsvm_svc:shrinking': 'False', 'classifier:libsvm_svc:tol': 5.910601434405198e-05, 'preprocessor:polynomial:degree': 3, 'preprocessor:polynomial:include_bias': 'False', 'preprocessor:polynomial:interaction_only': 'True', 'rescaling:quantile_transformer:n_quantiles': 1283, 'rescaling:quantile_transformer:output_distribution': 'normal', 'classifier:libsvm_svc:coef0': -0.7668243818208773, 'classifier:libsvm_svc:degree': 3},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.040000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'libsvm_svc', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'select_rates', 'rescaling:__choice__': 'minmax', 'classifier:libsvm_svc:C': 23.772751882238104, 'classifier:libsvm_svc:gamma': 1.095292537439119, 'classifier:libsvm_svc:kernel': 'rbf', 'classifier:libsvm_svc:max_iter': -1, 'classifier:libsvm_svc:shrinking': 'False', 'classifier:libsvm_svc:tol': 0.0012169319529746246, 'preprocessor:select_rates:alpha': 0.1524323004041074, 'preprocessor:select_rates:mode': 'fwe', 'preprocessor:select_rates:score_func': 'f_classif'},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'bernoulli_nb', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'select_rates', 'rescaling:__choice__': 'minmax', 'classifier:bernoulli_nb:alpha': 1.0, 'classifier:bernoulli_nb:fit_prior': 'True', 'preprocessor:select_rates:alpha': 0.38607389944150117, 'preprocessor:select_rates:mode': 'fdr', 'preprocessor:select_rates:score_func': 'chi2'},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'liblinear_svc', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'select_rates', 'rescaling:__choice__': 'standardize', 'classifier:liblinear_svc:C': 1.0, 'classifier:liblinear_svc:dual': 'False', 'classifier:liblinear_svc:fit_intercept': 'True', 'classifier:liblinear_svc:intercept_scaling': 1, 'classifier:liblinear_svc:loss': 'squared_hinge', 'classifier:liblinear_svc:multi_class': 'ovr', 'classifier:liblinear_svc:penalty': 'l2', 'classifier:liblinear_svc:tol': 0.00010000000000000009, 'preprocessor:select_rates:alpha': 0.38607389944150117, 'preprocessor:select_rates:mode': 'fdr', 'preprocessor:select_rates:score_func': 'chi2'},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'extra_trees', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'polynomial', 'rescaling:__choice__': 'minmax', 'classifier:extra_trees:bootstrap': 'True', 'classifier:extra_trees:criterion': 'entropy', 'classifier:extra_trees:max_depth': 'None', 'classifier:extra_trees:max_features': 0.4839956882733081, 'classifier:extra_trees:max_leaf_nodes': 'None', 'classifier:extra_trees:min_impurity_decrease': 0.0, 'classifier:extra_trees:min_samples_leaf': 16, 'classifier:extra_trees:min_samples_split': 17, 'classifier:extra_trees:min_weight_fraction_leaf': 0.0, 'classifier:extra_trees:n_estimators': 100, 'preprocessor:polynomial:degree': 2, 'preprocessor:polynomial:include_bias': 'False', 'preprocessor:polynomial:interaction_only': 'True'},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'extra_trees', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'select_rates', 'rescaling:__choice__': 'standardize', 'classifier:extra_trees:bootstrap': 'False', 'classifier:extra_trees:criterion': 'gini', 'classifier:extra_trees:max_depth': 'None', 'classifier:extra_trees:max_features': 0.2654780993733651, 'classifier:extra_trees:max_leaf_nodes': 'None', 'classifier:extra_trees:min_impurity_decrease': 0.0, 'classifier:extra_trees:min_samples_leaf': 13, 'classifier:extra_trees:min_samples_split': 20, 'classifier:extra_trees:min_weight_fraction_leaf': 0.0, 'classifier:extra_trees:n_estimators': 100, 'preprocessor:select_rates:alpha': 0.38607389944150117, 'preprocessor:select_rates:mode': 'fdr', 'preprocessor:select_rates:score_func': 'chi2'},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'lda', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'fast_ica', 'rescaling:__choice__': 'quantile_transformer', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False', 'classifier:lda:n_components': 34, 'classifier:lda:shrinkage': 'None', 'classifier:lda:tol': 0.0010962213170651273, 'preprocessor:fast_ica:algorithm': 'deflation', 'preprocessor:fast_ica:fun': 'exp', 'preprocessor:fast_ica:whiten': 'True', 'rescaling:quantile_transformer:n_quantiles': 358, 'rescaling:quantile_transformer:output_distribution': 'normal', 'preprocessor:fast_ica:n_components': 645},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'liblinear_svc', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'select_rates', 'rescaling:__choice__': 'standardize', 'classifier:liblinear_svc:C': 1.0, 'classifier:liblinear_svc:dual': 'False', 'classifier:liblinear_svc:fit_intercept': 'True', 'classifier:liblinear_svc:intercept_scaling': 1, 'classifier:liblinear_svc:loss': 'squared_hinge', 'classifier:liblinear_svc:multi_class': 'ovr', 'classifier:liblinear_svc:penalty': 'l2', 'classifier:liblinear_svc:tol': 0.00010000000000000009, 'preprocessor:select_rates:alpha': 0.2287536951631349, 'preprocessor:select_rates:mode': 'fdr', 'preprocessor:select_rates:score_func': 'f_classif'},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                     predictions_hd_ohe))\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "print('Sprint Stats:')\n",
    "print(automl_hd_ohe.sprint_statistics())\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "print('Model Details:')\n",
    "print(automl_hd_ohe.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the same thing (build a model on ohe data with holdout) but this time with parallelization turned on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting ../results/tmp_hd_holdout_parallel\n",
      "\n",
      "deleting ../results/out_hd_holdout_parallel\n",
      "\n",
      "[WARNING] [2021-12-02 19:19:38,870:EnsembleBuilder(953453411):heart_disease] No models better than random - using Dummy Score!\n",
      "[WARNING] [2021-12-02 19:19:38,877:EnsembleBuilder(953453411):heart_disease] No models better than random - using Dummy Score!\n",
      "CPU times: user 6.26 s, sys: 212 ms, total: 6.48 s\n",
      "Wall time: 55.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#set and clear the output directories\n",
    "directories_parallel = ['../results/tmp_hd_holdout_parallel', \\\n",
    "                        '../results/out_hd_holdout_parallel']\n",
    "cleanup(directories_parallel, True)\n",
    "\n",
    "#build the auto-sklearn routine\n",
    "automl_hd_ohe_p = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=60,\n",
    "    per_run_time_limit=30,\n",
    "    tmp_folder=directories_parallel[0],\n",
    "    output_folder=directories_parallel[1],\n",
    "    disable_evaluator_output=False,\n",
    "    resampling_strategy='holdout',\n",
    "    resampling_strategy_arguments={'train_size': 0.67},\n",
    "    \n",
    "    #turn on parallelization\n",
    "    n_jobs=4,\n",
    "    seed=5,\n",
    "    \n",
    "    delete_output_folder_after_terminate=False,\n",
    "    delete_tmp_folder_after_terminate=False,\n",
    ")\n",
    "\n",
    "#call it\n",
    "automl_hd_ohe_p.fit(X_hd_ohe_train, y_hd_ohe_train, \\\n",
    "                    dataset_name='heart_disease')\n",
    "\n",
    "#save the predicitons\n",
    "predictions_hd_ohe_p = automl_hd_ohe_p.predict(X_hd_ohe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.8157894736842105\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Sprint Stats:\n",
      "auto-sklearn results:\n",
      "  Dataset name: heart_disease\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.840000\n",
      "  Number of target algorithm runs: 17\n",
      "  Number of successful target algorithm runs: 9\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 8\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                     predictions_hd_ohe_p))\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "print('Sprint Stats:')\n",
    "print(automl_hd_ohe_p.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details:\n",
      "[(0.300000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'libsvm_svc', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'select_rates', 'rescaling:__choice__': 'minmax', 'classifier:libsvm_svc:C': 23.772751882238104, 'classifier:libsvm_svc:gamma': 1.095292537439119, 'classifier:libsvm_svc:kernel': 'rbf', 'classifier:libsvm_svc:max_iter': -1, 'classifier:libsvm_svc:shrinking': 'False', 'classifier:libsvm_svc:tol': 0.0012169319529746246, 'preprocessor:select_rates:alpha': 0.1524323004041074, 'preprocessor:select_rates:mode': 'fwe', 'preprocessor:select_rates:score_func': 'f_classif'},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.200000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'gaussian_nb', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'polynomial', 'rescaling:__choice__': 'standardize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False', 'preprocessor:polynomial:degree': 2, 'preprocessor:polynomial:include_bias': 'True', 'preprocessor:polynomial:interaction_only': 'False'},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.160000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'lda', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'extra_trees_preproc_for_classification', 'rescaling:__choice__': 'standardize', 'classifier:lda:n_components': 164, 'classifier:lda:shrinkage': 'auto', 'classifier:lda:tol': 0.011614193932275677, 'preprocessor:extra_trees_preproc_for_classification:bootstrap': 'False', 'preprocessor:extra_trees_preproc_for_classification:criterion': 'gini', 'preprocessor:extra_trees_preproc_for_classification:max_depth': 'None', 'preprocessor:extra_trees_preproc_for_classification:max_features': 0.5264611650711638, 'preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes': 'None', 'preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease': 0.0, 'preprocessor:extra_trees_preproc_for_classification:min_samples_leaf': 2, 'preprocessor:extra_trees_preproc_for_classification:min_samples_split': 4, 'preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf': 0.0, 'preprocessor:extra_trees_preproc_for_classification:n_estimators': 100},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.100000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'select_percentile_classification', 'rescaling:__choice__': 'minmax', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'False', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.03614409206795499, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 3, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'preprocessor:select_percentile_classification:percentile': 86.15284301822304, 'preprocessor:select_percentile_classification:score_func': 'f_classif', 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.010000000000000004},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.080000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'standardize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.01},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.080000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'decision_tree', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'quantile_transformer', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:decision_tree:criterion': 'entropy', 'classifier:decision_tree:max_depth_factor': 1.5305815818152393, 'classifier:decision_tree:max_features': 1.0, 'classifier:decision_tree:max_leaf_nodes': 'None', 'classifier:decision_tree:min_impurity_decrease': 0.0, 'classifier:decision_tree:min_samples_leaf': 11, 'classifier:decision_tree:min_samples_split': 18, 'classifier:decision_tree:min_weight_fraction_leaf': 0.0, 'rescaling:quantile_transformer:n_quantiles': 952, 'rescaling:quantile_transformer:output_distribution': 'normal', 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.0004867654228976359},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.040000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'k_nearest_neighbors', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'polynomial', 'rescaling:__choice__': 'standardize', 'classifier:k_nearest_neighbors:n_neighbors': 1, 'classifier:k_nearest_neighbors:p': 1, 'classifier:k_nearest_neighbors:weights': 'distance', 'preprocessor:polynomial:degree': 3, 'preprocessor:polynomial:include_bias': 'False', 'preprocessor:polynomial:interaction_only': 'False'},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.040000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'gaussian_nb', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'normalize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.026264369457685063},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print('Model Details:')\n",
    "print(automl_hd_ohe_p.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try with feat_type option instead of ohe (still using parallel and holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# #set and clear the output directories\n",
    "# directories_parallel_ft = ['../results/tmp_hd_holdout_parallel_ft', \\\n",
    "#                            '../results/out_hd_holdout_parallel_ft']\n",
    "# cleanup(directories_parallel_ft, True)\n",
    "\n",
    "# #build the auto-sklearn routine\n",
    "# automl_hd_ft_p = autosklearn.classification.AutoSklearnClassifier(\n",
    "#     time_left_for_this_task=60,\n",
    "#     per_run_time_limit=30,\n",
    "#     tmp_folder=directories_parallel_ft[0],\n",
    "#     output_folder=directories_parallel_ft[1],\n",
    "#     disable_evaluator_output=False,\n",
    "#     # 'holdout' with 'train_size'=0.67 is the default argument setting\n",
    "#     # for AutoSklearnClassifier. It is explicitly specified in this example\n",
    "#     # for demonstrational purpose.\n",
    "#     resampling_strategy='holdout',\n",
    "#     resampling_strategy_arguments={'train_size': 0.67},\n",
    "#     n_jobs=4,\n",
    "#     seed=5,\n",
    "#     delete_output_folder_after_terminate=False,\n",
    "#     delete_tmp_folder_after_terminate=False,\n",
    "# )\n",
    "\n",
    "# feat_type = ['Numerical','Numerical','Categorical','Numerical',\\\n",
    "#              'Numerical', 'Numerical','Categorical', 'Numerical',\\\n",
    "#              'Numerical','Numerical', 'Categorical','Numerical',\\\n",
    "#              'Categorical']\n",
    "\n",
    "# #call it\n",
    "# automl_hd_ft_p.fit(X_hd_train, y_hd_train, \\\n",
    "#                    dataset_name='heart_disease', feat_type=feat_type)\n",
    "\n",
    "# #save the predicitons\n",
    "# predictions_hd_ft_p = automl_hd_ft_p.predict(X_hd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Accuracy:')\n",
    "# print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "#                                      predictions_hd_ft_p))\n",
    "# print(' ')\n",
    "# print('-----------------------------------------')\n",
    "# print(' ')\n",
    "# print('Sprint Stats:')\n",
    "# print(automl_hd_ft_p.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Model Details:')\n",
    "# print(automl_hd_ft_p.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try with CV instead of Holdout (using ohe and parallel)\n",
    "\n",
    "CV requires an extra step to fit our ensemble on all the data. During **fit()**, models are fit on individual cross-validation folds. To use all available data, we call **refit()** which trains all models in the final ensemble on the whole dataset. Also, when using CV, **fit()** changes the data in place, but refit needs the original data. So we use the **copy()** function. In practice, you might want to reload the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# #set and clear the output directories\n",
    "# directories_parallel_cv = ['../results/tmp_hd_holdout_parallel_cv', \\\n",
    "#                            '../results/out_hd_holdout_parallel_cv']\n",
    "# cleanup(directories_parallel_cv, True)\n",
    "\n",
    "# #build the auto-sklearn routine\n",
    "# automl_hd_cv_p = autosklearn.classification.AutoSklearnClassifier(\n",
    "#     time_left_for_this_task=60,\n",
    "#     per_run_time_limit=30,\n",
    "#     tmp_folder=directories_parallel_cv[0],\n",
    "#     output_folder=directories_parallel_cv[1],\n",
    "#     disable_evaluator_output=False,\n",
    "#     # 'holdout' with 'train_size'=0.67 is the default argument setting\n",
    "#     # for AutoSklearnClassifier. It is explicitly specified in this example\n",
    "#     # for demonstrational purpose.\n",
    "#     resampling_strategy='cv',\n",
    "#     resampling_strategy_arguments={'folds': 5},\n",
    "#     n_jobs=4,\n",
    "#     seed=5,\n",
    "#     delete_output_folder_after_terminate=False,\n",
    "#     delete_tmp_folder_after_terminate=False,\n",
    "# )\n",
    "\n",
    "# #call it\n",
    "# automl_hd_cv_p.fit(X_hd_ohe_train.copy(), y_hd_ohe_train.copy(), \\\n",
    "#                    dataset_name='heart_disease')\n",
    "# automl_hd_cv_p.refit(X_hd_ohe_train.copy(), y_hd_ohe_train.copy())\n",
    "\n",
    "# #save the predicitons\n",
    "# predictions_hd_cv_p = automl_hd_cv_p.predict(X_hd_ohe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Accuracy:')\n",
    "# print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "#                                      predictions_hd_cv_p))\n",
    "# print(' ')\n",
    "# print('-----------------------------------------')\n",
    "# print(' ')\n",
    "# print('Sprint Stats:')\n",
    "# print(automl_hd_cv_p.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Model Details:')\n",
    "# print(automl_hd_cv_p.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the breast cancer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "print(sklearn.datasets.load_breast_cancer()['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load from sklearn\n",
    "X_bc, y_bc = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "\n",
    "#build the train and test sets\n",
    "X_bc_train, X_bc_test, y_bc_train, y_bc_test = \\\n",
    "    sklearn.model_selection.train_test_split(X_bc, y_bc, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a model using holdout and parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting ../results/tmp_bc\n",
      "\n",
      "deleting ../results/out_bc\n",
      "\n",
      "[WARNING] [2021-12-02 19:20:34,656:EnsembleBuilder(953453411):breast_cancer] No models better than random - using Dummy Score!\n",
      "[WARNING] [2021-12-02 19:20:34,663:EnsembleBuilder(953453411):breast_cancer] No models better than random - using Dummy Score!\n",
      "CPU times: user 6.64 s, sys: 208 ms, total: 6.85 s\n",
      "Wall time: 55.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#set and clear the output directorie\n",
    "directories_bc = ['../results/tmp_bc', '../results/out_bc']\n",
    "cleanup(directories_bc, True)\n",
    "\n",
    "#build the auto-sklearn routine\n",
    "automl_bc = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=60,\n",
    "    per_run_time_limit=30,\n",
    "    tmp_folder=directories_bc[0],\n",
    "    output_folder=directories_bc[1],\n",
    "    disable_evaluator_output=False,\n",
    "    # 'holdout' with 'train_size'=0.67 is the default argument setting\n",
    "    # for AutoSklearnClassifier. It is explicitly specified in this example\n",
    "    # for demonstrational purpose.\n",
    "    resampling_strategy='holdout',\n",
    "    resampling_strategy_arguments={'train_size': 0.67},\n",
    "    n_jobs=4,\n",
    "    seed=5,\n",
    "    delete_output_folder_after_terminate=False,\n",
    "    delete_tmp_folder_after_terminate=False,\n",
    ")\n",
    "\n",
    "#call it\n",
    "automl_bc.fit(X_bc_train, y_bc_train, dataset_name='breast_cancer')\n",
    "\n",
    "#save the predicitons\n",
    "predictions_bc = automl_bc.predict(X_bc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.958041958041958\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Sprint Stats:\n",
      "auto-sklearn results:\n",
      "  Dataset name: breast_cancer\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.978723\n",
      "  Number of target algorithm runs: 13\n",
      "  Number of successful target algorithm runs: 5\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 8\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(sklearn.metrics.accuracy_score(y_bc_test, \\\n",
    "                                     predictions_bc))\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "print('Sprint Stats:')\n",
    "print(automl_bc.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details:\n",
      "[(0.240000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'select_percentile_classification', 'rescaling:__choice__': 'minmax', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'False', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.03614409206795499, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 3, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'preprocessor:select_percentile_classification:percentile': 86.15284301822304, 'preprocessor:select_percentile_classification:score_func': 'f_classif', 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.010000000000000004},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.240000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'lda', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'extra_trees_preproc_for_classification', 'rescaling:__choice__': 'standardize', 'classifier:lda:n_components': 164, 'classifier:lda:shrinkage': 'auto', 'classifier:lda:tol': 0.011614193932275677, 'preprocessor:extra_trees_preproc_for_classification:bootstrap': 'False', 'preprocessor:extra_trees_preproc_for_classification:criterion': 'gini', 'preprocessor:extra_trees_preproc_for_classification:max_depth': 'None', 'preprocessor:extra_trees_preproc_for_classification:max_features': 0.5264611650711638, 'preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes': 'None', 'preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease': 0.0, 'preprocessor:extra_trees_preproc_for_classification:min_samples_leaf': 2, 'preprocessor:extra_trees_preproc_for_classification:min_samples_split': 4, 'preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf': 0.0, 'preprocessor:extra_trees_preproc_for_classification:n_estimators': 100},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.200000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'standardize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.01},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.200000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'k_nearest_neighbors', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'polynomial', 'rescaling:__choice__': 'standardize', 'classifier:k_nearest_neighbors:n_neighbors': 1, 'classifier:k_nearest_neighbors:p': 1, 'classifier:k_nearest_neighbors:weights': 'distance', 'preprocessor:polynomial:degree': 3, 'preprocessor:polynomial:include_bias': 'False', 'preprocessor:polynomial:interaction_only': 'False'},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "(0.120000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'gaussian_nb', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'normalize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.026264369457685063},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print('Model Details:')\n",
    "print(automl_bc.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Run and Accuracy Stats\n",
    "\n",
    "All in one place for easier comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Heart Disease---------------\n",
      " \n",
      " \n",
      "Model stats HD Holdout:\n",
      "auto-sklearn results:\n",
      "  Dataset name: heart_disease\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.893333\n",
      "  Number of target algorithm runs: 72\n",
      "  Number of successful target algorithm runs: 68\n",
      "  Number of crashed target algorithm runs: 4\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      " \n",
      "Accuracy score HD Holdout:\n",
      "0.75\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Model stats HD Holdout Parallel:\n",
      "auto-sklearn results:\n",
      "  Dataset name: heart_disease\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.840000\n",
      "  Number of target algorithm runs: 17\n",
      "  Number of successful target algorithm runs: 9\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 8\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      "Accuracy score HD Holdout Parallel:\n",
      "0.8157894736842105\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      " \n",
      " \n",
      "-----------Breast Cancer---------------\n",
      " \n",
      " \n",
      "Model stats BC Holdout Parallel:\n",
      "auto-sklearn results:\n",
      "  Dataset name: breast_cancer\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.978723\n",
      "  Number of target algorithm runs: 13\n",
      "  Number of successful target algorithm runs: 5\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 8\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      " \n",
      "Accuracy score BC Holdout Parallel:\n",
      "0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------Heart Disease---------------\")\n",
    "print(' ')\n",
    "print(' ')\n",
    "\n",
    "print(\"Model stats HD Holdout:\")\n",
    "print(automl_hd_ohe.sprint_statistics())\n",
    "print(' ')\n",
    "print(\"Accuracy score HD Holdout:\")\n",
    "print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                     predictions_hd_ohe))\n",
    "\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "\n",
    "print(\"Model stats HD Holdout Parallel:\")\n",
    "print(automl_hd_ohe_p.sprint_statistics())\n",
    "print(\"Accuracy score HD Holdout Parallel:\")\n",
    "print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                     predictions_hd_ohe_p))\n",
    "\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "\n",
    "# #holdout parallel feat_type\n",
    "# print(\"Model stats HD Holdout Feature Type Parallel:\")\n",
    "# print(automl_hd_ft_p.sprint_statistics())\n",
    "# print(' ')\n",
    "# print(\"Accuracy score HD Holdout Feature Type Parallel:\")\n",
    "# print(sklearn.metrics.accuracy_score(y_hd_test, \\\n",
    "#                                      predictions_hd_ft_p))\n",
    "\n",
    "# print(' ')\n",
    "# print('-----------------------------------------')\n",
    "# print(' ')\n",
    "\n",
    "# #cross validation parallel\n",
    "# print(\"Model stats HD CV Parllel:\")\n",
    "# print(automl_hd_cv_p.sprint_statistics())\n",
    "# print(' ')\n",
    "# print(\"Accuracy score HD CV Parallel:\")\n",
    "# print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "#                                      predictions_hd_cv_p))\n",
    "\n",
    "print(' ')\n",
    "print(' ')\n",
    "\n",
    "print(\"-----------Breast Cancer---------------\")\n",
    "print(' ')\n",
    "print(' ')\n",
    "\n",
    "print(\"Model stats BC Holdout Parallel:\")\n",
    "print(automl_bc.sprint_statistics())\n",
    "print(' ')\n",
    "print(\"Accuracy score BC Holdout Parallel:\")\n",
    "print(sklearn.metrics.accuracy_score(y_bc_test, \\\n",
    "                                     predictions_bc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Ensemble to Disk\n",
    "\n",
    "In the specific case of [scikit-learn](https://scikit-learn.org/stable/modules/model_persistence.html#persistence-example), it may be better to use joblib’s replacement of pickle (dump & load), which is more efficient on objects that carry large numpy arrays internally as is often the case for fitted scikit-learn estimators, but can only pickle to the disk and not to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../results/autosklearn_bc.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(automl_bc, '../results/autosklearn_bc.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Domino Stats File\n",
    "\n",
    "To keep things simple, we pick one of the hd models. Saving stats to this file [allows Domino to track and trend them in the Experiment Manager](https://support.dominodatalab.com/hc/en-us/articles/204348169-Diagnostic-statistics-with-dominostats-json) when this notebook is run as a batch or scheduled job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_acc = sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                        predictions_hd_ohe_p)\n",
    "bc_acc = sklearn.metrics.accuracy_score(y_bc_test, \\\n",
    "                                        predictions_bc)\n",
    "\n",
    "import json\n",
    "with open('../dominostats.json', 'w') as f:\n",
    "    f.write(json.dumps( {\"HD_ACC\": hd_acc, \"BC_ACC\": bc_acc}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
