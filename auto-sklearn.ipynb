{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auto-sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author's description:\n",
    "\n",
    "auto-sklearn is an automated machine learning toolkit and a drop-in replacement for a scikit-learn estimator\n",
    "\n",
    "#### Useful links:\n",
    "\n",
    "[install link](https://automl.github.io/auto-sklearn/master/installation.html),\n",
    "[git](https://github.com/automl/auto-sklearn),\n",
    "[manual](https://automl.github.io/auto-sklearn/master/manual.html),\n",
    "[parallel instances](https://automl.github.io/auto-sklearn/master/examples/example_parallel_manual_spawning.html),\n",
    "[parallel runs on one machine](https://automl.github.io/auto-sklearn/master/examples/example_parallel_n_jobs.html),\n",
    "[cross validation](https://automl.github.io/auto-sklearn/master/examples/example_crossvalidation.html),\n",
    "[feature types](https://automl.github.io/auto-sklearn/master/examples/example_feature_types.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auto-sklearn builds ensembles, provides good control of the auto-ML run details, and makes exporting easy due to its scikit-learn foundations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: auto-sklearn in /home/ubuntu/.local/lib/python3.8/site-packages (0.14.7)\n",
      "Requirement already satisfied: scikit-learn<0.25.0,>=0.24.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from auto-sklearn) (0.24.2)\n",
      "Requirement already satisfied: smac<1.3,>=1.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from auto-sklearn) (1.2)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from auto-sklearn) (1.21.5)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from auto-sklearn) (1.1.0)\n",
      "Requirement already satisfied: liac-arff in /home/ubuntu/.local/lib/python3.8/site-packages (from auto-sklearn) (2.5.0)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/.local/lib/python3.8/site-packages (from auto-sklearn) (6.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from auto-sklearn) (60.9.3)\n",
      "Requirement already satisfied: distro in /home/ubuntu/.local/lib/python3.8/site-packages (from auto-sklearn) (1.7.0)\n",
      "Requirement already satisfied: distributed>=2012.12 in /home/ubuntu/.local/lib/python3.8/site-packages (from auto-sklearn) (2022.8.0)\n",
      "Requirement already satisfied: pandas>=1.0 in /opt/conda/lib/python3.8/site-packages (from auto-sklearn) (1.3.5)\n",
      "Requirement already satisfied: ConfigSpace<0.5,>=0.4.21 in /home/ubuntu/.local/lib/python3.8/site-packages (from auto-sklearn) (0.4.21)\n",
      "Requirement already satisfied: pyrfr<0.9,>=0.8.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from auto-sklearn) (0.8.3)\n",
      "Requirement already satisfied: pynisher<0.7,>=0.6.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from auto-sklearn) (0.6.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.8/site-packages (from auto-sklearn) (1.7.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from auto-sklearn) (4.1.1)\n",
      "Requirement already satisfied: dask>=2021.12 in /home/ubuntu/.local/lib/python3.8/site-packages (from auto-sklearn) (2022.8.0)\n",
      "Requirement already satisfied: threadpoolctl in /opt/conda/lib/python3.8/site-packages (from auto-sklearn) (3.1.0)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.8/site-packages (from ConfigSpace<0.5,>=0.4.21->auto-sklearn) (3.0.7)\n",
      "Requirement already satisfied: cython in /home/ubuntu/.local/lib/python3.8/site-packages (from ConfigSpace<0.5,>=0.4.21->auto-sklearn) (0.29.32)\n",
      "Requirement already satisfied: partd>=0.3.10 in /home/ubuntu/.local/lib/python3.8/site-packages (from dask>=2021.12->auto-sklearn) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from dask>=2021.12->auto-sklearn) (21.3)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from dask>=2021.12->auto-sklearn) (2.1.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from dask>=2021.12->auto-sklearn) (0.12.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from dask>=2021.12->auto-sklearn) (2022.7.1)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from distributed>=2012.12->auto-sklearn) (1.7.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from distributed>=2012.12->auto-sklearn) (1.0.4)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.local/lib/python3.8/site-packages (from distributed>=2012.12->auto-sklearn) (3.0.3)\n",
      "Requirement already satisfied: locket>=1.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from distributed>=2012.12->auto-sklearn) (1.0.0)\n",
      "Requirement already satisfied: click>=6.6 in /home/ubuntu/.local/lib/python3.8/site-packages (from distributed>=2012.12->auto-sklearn) (8.0.4)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from distributed>=2012.12->auto-sklearn) (2.4.0)\n",
      "Requirement already satisfied: tornado<6.2,>=6.0.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from distributed>=2012.12->auto-sklearn) (6.1)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.8/site-packages (from distributed>=2012.12->auto-sklearn) (1.26.6)\n",
      "Requirement already satisfied: psutil>=5.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from distributed>=2012.12->auto-sklearn) (5.9.1)\n",
      "Requirement already satisfied: zict>=0.1.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from distributed>=2012.12->auto-sklearn) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.0->auto-sklearn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.0->auto-sklearn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=1.0->auto-sklearn) (1.16.0)\n",
      "Requirement already satisfied: emcee>=3.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from smac<1.3,>=1.2->auto-sklearn) (3.1.2)\n",
      "Requirement already satisfied: heapdict in /home/ubuntu/.local/lib/python3.8/site-packages (from zict>=0.1.3->distributed>=2012.12->auto-sklearn) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from jinja2->distributed>=2012.12->auto-sklearn) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install auto-sklearn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noriginal verision of auto-sklearn used\\ndid not capture original versions of other libraries like sklearn\\ndoesn't work on a new compute environment due to version mismatches\\nbest approach is to try on current latest versions of everything\\nand then freeze all the package versions once it is working again\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install auto-sklearn==0.6.0 --user\n",
    "\"\"\"\n",
    "original verision of auto-sklearn used\n",
    "did not capture original versions of other libraries like sklearn\n",
    "doesn't work on a new compute environment due to version mismatches\n",
    "best approach is to try on current latest versions of everything\n",
    "and then freeze all the package versions once it is working again\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *---You may need to restart the kernel after install and run again starting here---*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there can be a lot of warnings in auto-sklearn\n",
    "#especially if you overwrite existing files\n",
    "#turning off for demo purposes\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the classification function\n",
    "\n",
    "auto-sklearnÂ is mostly a wrapper around scikit-learn. It was not the intention of the authors to allow user control over details such as the modeling algorithm and typical hyper-parameter choices. Control is several layers deep in the [SMAC](https://automl.github.io/SMAC3/master/) space and scenario settings. The user can control the time is takes to build the ensemble, the resampling strategy and the parallelization of the work across CPUs on the machine. These will be demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mautosklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoSklearnClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtime_left_for_this_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mper_run_time_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minitial_configurations_via_metalearning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mensemble_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mensemble_nbest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_models_on_disc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmemory_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3072\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minclude\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'holdout'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresampling_strategy_arguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtmp_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelete_tmp_folder_after_terminate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdask_client\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdisable_evaluator_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mget_smac_object_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msmac_scenario_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogging_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetadata_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscoring_functions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mautosklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScorer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mload_models\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mget_trials_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      This class implements the classification task.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Parameters\n",
       "----------\n",
       "time_left_for_this_task : int, optional (default=3600)\n",
       "    Time limit in seconds for the search of appropriate\n",
       "    models. By increasing this value, *auto-sklearn* has a higher\n",
       "    chance of finding better models.\n",
       "\n",
       "per_run_time_limit : int, optional (default=1/10 of time_left_for_this_task)\n",
       "    Time limit for a single call to the machine learning model.\n",
       "    Model fitting will be terminated if the machine learning\n",
       "    algorithm runs over the time limit. Set this value high enough so\n",
       "    that typical machine learning algorithms can be fit on the\n",
       "    training data.\n",
       "\n",
       "initial_configurations_via_metalearning : int, optional (default=25)\n",
       "    Initialize the hyperparameter optimization algorithm with this\n",
       "    many configurations which worked well on previously seen\n",
       "    datasets. Disable if the hyperparameter optimization algorithm\n",
       "    should start from scratch.\n",
       "\n",
       "ensemble_size : int, optional (default=50)\n",
       "    Number of models added to the ensemble built by *Ensemble\n",
       "    selection from libraries of models*. Models are drawn with\n",
       "    replacement. If set to ``0`` no ensemble is fit.\n",
       "\n",
       "ensemble_nbest : int, optional (default=50)\n",
       "    Only consider the ``ensemble_nbest`` models when building an\n",
       "    ensemble.\n",
       "\n",
       "max_models_on_disc: int, optional (default=50),\n",
       "    Defines the maximum number of models that are kept in the disc.\n",
       "    The additional number of models are permanently deleted. Due to the\n",
       "    nature of this variable, it sets the upper limit on how many models\n",
       "    can be used for an ensemble.\n",
       "    It must be an integer greater or equal than 1.\n",
       "    If set to None, all models are kept on the disc.\n",
       "\n",
       "seed : int, optional (default=1)\n",
       "    Used to seed SMAC. Will determine the output file names.\n",
       "\n",
       "memory_limit : int, optional (3072)\n",
       "    Memory limit in MB for the machine learning algorithm.\n",
       "    `auto-sklearn` will stop fitting the machine learning algorithm if\n",
       "    it tries to allocate more than ``memory_limit`` MB.\n",
       "\n",
       "    **Important notes:**\n",
       "\n",
       "    * If ``None`` is provided, no memory limit is set.\n",
       "    * In case of multi-processing, ``memory_limit`` will be *per job*, so the total usage is\n",
       "      ``n_jobs x memory_limit``.\n",
       "    * The memory limit also applies to the ensemble creation process.\n",
       "\n",
       "include : Optional[Dict[str, List[str]]] = None\n",
       "    If None, all possible algorithms are used.\n",
       "\n",
       "    Otherwise, specifies a step and the components that are included in search.\n",
       "    See ``/pipeline/components/<step>/*`` for available components.\n",
       "\n",
       "    Incompatible with parameter ``exclude``.\n",
       "\n",
       "    **Possible Steps**:\n",
       "\n",
       "    * ``\"data_preprocessor\"``\n",
       "    * ``\"balancing\"``\n",
       "    * ``\"feature_preprocessor\"``\n",
       "    * ``\"classifier\"`` - Only for when when using ``AutoSklearnClasssifier``\n",
       "    * ``\"regressor\"`` - Only for when when using ``AutoSklearnRegressor``\n",
       "\n",
       "    **Example**:\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        include = {\n",
       "            'classifier': [\"random_forest\"],\n",
       "            'feature_preprocessor': [\"no_preprocessing\"]\n",
       "        }\n",
       "\n",
       "exclude : Optional[Dict[str, List[str]]] = None\n",
       "    If None, all possible algorithms are used.\n",
       "\n",
       "    Otherwise, specifies a step and the components that are excluded from search.\n",
       "    See ``/pipeline/components/<step>/*`` for available components.\n",
       "\n",
       "    Incompatible with parameter ``include``.\n",
       "\n",
       "    **Possible Steps**:\n",
       "\n",
       "    * ``\"data_preprocessor\"``\n",
       "    * ``\"balancing\"``\n",
       "    * ``\"feature_preprocessor\"``\n",
       "    * ``\"classifier\"`` - Only for when when using ``AutoSklearnClasssifier``\n",
       "    * ``\"regressor\"`` - Only for when when using ``AutoSklearnRegressor``\n",
       "\n",
       "    **Example**:\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        exclude = {\n",
       "            'classifier': [\"random_forest\"],\n",
       "            'feature_preprocessor': [\"no_preprocessing\"]\n",
       "        }\n",
       "\n",
       "resampling_strategy : string or object, optional ('holdout')\n",
       "    how to to handle overfitting, might need 'resampling_strategy_arguments'\n",
       "\n",
       "    * 'holdout': 67:33 (train:test) split\n",
       "    * 'holdout-iterative-fit':  67:33 (train:test) split, calls iterative\n",
       "      fit where possible\n",
       "    * 'cv': crossvalidation, requires 'folds'\n",
       "    * 'cv-iterative-fit': crossvalidation, calls iterative fit where possible\n",
       "    * 'partial-cv': crossvalidation with intensification, requires\n",
       "      'folds'\n",
       "    * BaseCrossValidator object: any BaseCrossValidator class found\n",
       "                                in scikit-learn model_selection module\n",
       "    * _RepeatedSplits object: any _RepeatedSplits class found\n",
       "                              in scikit-learn model_selection module\n",
       "    * BaseShuffleSplit object: any BaseShuffleSplit class found\n",
       "                              in scikit-learn model_selection module\n",
       "\n",
       "resampling_strategy_arguments : dict, optional if 'holdout' (train_size default=0.67)\n",
       "    Additional arguments for resampling_strategy:\n",
       "\n",
       "    * ``train_size`` should be between 0.0 and 1.0 and represent the\n",
       "      proportion of the dataset to include in the train split.\n",
       "    * ``shuffle`` determines whether the data is shuffled prior to\n",
       "      splitting it into train and validation.\n",
       "\n",
       "    Available arguments:\n",
       "\n",
       "    * 'holdout': {'train_size': float}\n",
       "    * 'holdout-iterative-fit':  {'train_size': float}\n",
       "    * 'cv': {'folds': int}\n",
       "    * 'cv-iterative-fit': {'folds': int}\n",
       "    * 'partial-cv': {'folds': int, 'shuffle': bool}\n",
       "    * BaseCrossValidator or _RepeatedSplits or BaseShuffleSplit object: all arguments\n",
       "      required by chosen class as specified in scikit-learn documentation.\n",
       "      If arguments are not provided, scikit-learn defaults are used.\n",
       "      If no defaults are available, an exception is raised.\n",
       "      Refer to the 'n_splits' argument as 'folds'.\n",
       "\n",
       "tmp_folder : string, optional (None)\n",
       "    folder to store configuration output and log files, if ``None``\n",
       "    automatically use ``/tmp/autosklearn_tmp_$pid_$random_number``\n",
       "\n",
       "delete_tmp_folder_after_terminate: bool, optional (True)\n",
       "    remove tmp_folder, when finished. If tmp_folder is None\n",
       "    tmp_dir will always be deleted\n",
       "\n",
       "n_jobs : int, optional, experimental\n",
       "    The number of jobs to run in parallel for ``fit()``. ``-1`` means\n",
       "    using all processors. \n",
       "    \n",
       "    **Important notes**: \n",
       "    \n",
       "    * By default, Auto-sklearn uses one core. \n",
       "    * Ensemble building is not affected by ``n_jobs`` but can be controlled by the number \n",
       "      of models in the ensemble.\n",
       "    * ``predict()`` is not affected by ``n_jobs`` (in contrast to most scikit-learn models)\n",
       "    * If ``dask_client`` is ``None``, a new dask client is created.\n",
       "\n",
       "dask_client : dask.distributed.Client, optional\n",
       "    User-created dask client, can be used to start a dask cluster and then\n",
       "    attach auto-sklearn to it.\n",
       "\n",
       "disable_evaluator_output: bool or list, optional (False)\n",
       "    If True, disable model and prediction output. Cannot be used\n",
       "    together with ensemble building. ``predict()`` cannot be used when\n",
       "    setting this True. Can also be used as a list to pass more\n",
       "    fine-grained information on what to save. Allowed elements in the\n",
       "    list are:\n",
       "\n",
       "    * ``'y_optimization'`` : do not save the predictions for the\n",
       "      optimization/validation set, which would later on be used to build\n",
       "      an ensemble.\n",
       "    * ``model`` : do not save any model files\n",
       "\n",
       "smac_scenario_args : dict, optional (None)\n",
       "    Additional arguments inserted into the scenario of SMAC. See the\n",
       "    `SMAC documentation <https://automl.github.io/SMAC3/master/pages/details/scenario.html>`_\n",
       "    for a list of available arguments.\n",
       "\n",
       "get_smac_object_callback : callable\n",
       "    Callback function to create an object of class\n",
       "    `smac.optimizer.smbo.SMBO <https://automl.github.io/SMAC3/master/apidoc/smac.optimizer.smbo.html>`_.\n",
       "    The function must accept the arguments ``scenario_dict``,\n",
       "    ``instances``, ``num_params``, ``runhistory``, ``seed`` and ``ta``.\n",
       "    This is an advanced feature. Use only if you are familiar with\n",
       "    `SMAC <https://automl.github.io/SMAC3/master/index.html>`_.\n",
       "\n",
       "logging_config : dict, optional (None)\n",
       "    dictionary object specifying the logger configuration. If None,\n",
       "    the default logging.yaml file is used, which can be found in\n",
       "    the directory ``util/logging.yaml`` relative to the installation.\n",
       "\n",
       "metadata_directory : str, optional (None)\n",
       "    path to the metadata directory. If None, the default directory\n",
       "    (autosklearn.metalearning.files) is used.\n",
       "\n",
       "metric : Scorer, optional (None)\n",
       "    An instance of :class:`autosklearn.metrics.Scorer` as created by\n",
       "    :meth:`autosklearn.metrics.make_scorer`. These are the `Built-in\n",
       "    Metrics`_.\n",
       "    If None is provided, a default metric is selected depending on the task.\n",
       "\n",
       "scoring_functions : List[Scorer], optional (None)\n",
       "    List of scorers which will be calculated for each pipeline and results will be\n",
       "    available via ``cv_results``\n",
       "\n",
       "load_models : bool, optional (True)\n",
       "    Whether to load the models after fitting Auto-sklearn.\n",
       "   \n",
       "get_trials_callback: callable\n",
       "    Callback function to create an object of subclass defined in module\n",
       "    `smac.callbacks <https://automl.github.io/SMAC3/master/apidoc/smac.callbacks.html>`_.\n",
       "    This is an advanced feature. Use only if you are familiar with\n",
       "    `SMAC <https://automl.github.io/SMAC3/master/index.html>`_.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "\n",
       "cv_results_ : dict of numpy (masked) ndarrays\n",
       "    A dict with keys as column headers and values as columns, that can be\n",
       "    imported into a pandas ``DataFrame``.\n",
       "\n",
       "    Not all keys returned by scikit-learn are supported yet.\n",
       "\n",
       "performance_over_time_ : pandas.core.frame.DataFrame\n",
       "    A ``DataFrame`` containing the models performance over time data. Can be\n",
       "    used for plotting directly. Please refer to the example\n",
       "    :ref:`Train and Test Inputs <sphx_glr_examples_40_advanced_example_pandas_train_test.py>`.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.8/site-packages/autosklearn/estimators.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?autosklearn.classification.AutoSklearnClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the heart disease dataset\n",
    "\n",
    "Note that in this cell we are calling **sklearn.model_selection.train_test_split()** twice and creating two sets of heart disease (hd) data for model fitting and testing. One is for the hd data without one hot encoding (ohe) and the other has the ohe columns. \n",
    "\n",
    "auto-sklearn accepts a list of categorical features and has several methods for treating categorical data. In this notebook we try both approaches - building ohe columns ourselves and letting auto-sklearn do its thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "/mnt/data/raw/heart.csv\n",
    "\n",
    "attribute documentation:\n",
    "      age: age in years\n",
    "      sex: sex (1 = male; 0 = female)\n",
    "      cp: chest pain type\n",
    "        -- Value 1: typical angina\n",
    "        -- Value 2: atypical angina\n",
    "        -- Value 3: non-anginal pain\n",
    "        -- Value 4: asymptomatic\n",
    "     trestbps: resting blood pressure (in mm Hg on admission to the \n",
    "        hospital)\n",
    "     chol: serum cholestoral in mg/dl\n",
    "     fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "     restecg: resting electrocardiographic results\n",
    "        -- Value 0: normal\n",
    "        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \n",
    "                    elevation or depression of > 0.05 mV)\n",
    "        -- Value 2: showing probable or definite left ventricular hypertrophy\n",
    "                    by Estes' criteria\n",
    "     thalach: maximum heart rate achieved\n",
    "     exang: exercise induced angina (1 = yes; 0 = no)\n",
    "     oldpeak = ST depression induced by exercise relative to rest\n",
    "     slope: the slope of the peak exercise ST segment\n",
    "        -- Value 1: upsloping\n",
    "        -- Value 2: flat\n",
    "        -- Value 3: downsloping\n",
    "     ca: number of major vessels (0-3) colored by flourosopy\n",
    "     thal: \n",
    "         3 = normal; \n",
    "         6 = fixed defect; \n",
    "         7 = reversable defect\n",
    "     target: diagnosis of heart disease (angiographic disease status)\n",
    "        -- Value 0: < 50% diameter narrowing\n",
    "        -- Value 1: > 50% diameter narrowing\n",
    " '''\n",
    "\n",
    "#load and clean the data----------------------\n",
    "\n",
    "#column names\n",
    "names = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang', \\\n",
    "         'oldpeak','slope','ca','thal','target']\n",
    "\n",
    "#load data from Domino project directory\n",
    "hd_data = pd.read_csv(\"./data/raw/heart.csv\", header=None, names=names)\n",
    "\n",
    "#in case some data comes in as string\n",
    "#convert to numeric and coerce errors to NaN\n",
    "for col in hd_data.columns:  # Iterate over chosen columns\n",
    "    hd_data[col] = pd.to_numeric(hd_data[col], errors='coerce')\n",
    "    \n",
    "#drop nulls\n",
    "hd_data.dropna(inplace=True)\n",
    "\n",
    "#non-ohe data---------------------------------\n",
    "   \n",
    "#load the X and y set as a numpy array\n",
    "X_hd = hd_data.drop('target', axis=1).values\n",
    "y_hd = hd_data['target'].values\n",
    "\n",
    "#build the train and test sets\n",
    "X_hd_train, X_hd_test, y_hd_train, y_hd_test = \\\n",
    "    sklearn.model_selection.train_test_split(X_hd, y_hd, random_state=12)\n",
    "\n",
    "#now do ohe-----------------------------------\n",
    "\n",
    "#function to do one hot encoding for categorical columns\n",
    "def create_dummies(data, cols, drop1st=True):\n",
    "    for c in cols:\n",
    "        dummies_df = pd.get_dummies(data[c], prefix=c, drop_first=drop1st)  \n",
    "        data=pd.concat([data, dummies_df], axis=1)\n",
    "        data = data.drop([c], axis=1)\n",
    "    return data\n",
    "\n",
    "cat_cols = ['cp', 'restecg', 'slope', 'ca', 'thal']\n",
    "hd_data = create_dummies(hd_data, cat_cols)\n",
    "    \n",
    "#load the X and y set as a numpy array\n",
    "X_hd_ohe = hd_data.drop('target', axis=1).values\n",
    "y_hd_ohe = hd_data['target'].values\n",
    "\n",
    "#build the train and test sets\n",
    "X_hd_ohe_train, X_hd_ohe_test, y_hd_ohe_train, y_hd_ohe_test = \\\n",
    "    sklearn.model_selection.train_test_split(X_hd_ohe, y_hd_ohe, \\\n",
    "                                             random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a model on ohe data with holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2022-08-11 15:17:17,395:Client-AutoML(1):heart_disease] Capping the per_run_time_limit to 29.0 to have time for a least 2 models in each process.\n",
      "CPU times: user 5.51 s, sys: 455 ms, total: 5.96 s\n",
      "Wall time: 57.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#build the auto-sklearn routine\n",
    "automl_hd_ohe = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=60,\n",
    "    per_run_time_limit=30,\n",
    "    disable_evaluator_output=False,\n",
    "    resampling_strategy='holdout',\n",
    "    resampling_strategy_arguments={'train_size': 0.67}\n",
    ")\n",
    "\n",
    "#call it\n",
    "automl_hd_ohe.fit(X_hd_ohe_train, y_hd_ohe_train, \\\n",
    "                  dataset_name='heart_disease')\n",
    "\n",
    "#save the predicitons\n",
    "predictions_hd_ohe = automl_hd_ohe.predict(X_hd_ohe_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting with autosklearn\n",
    "\n",
    "A common mistake is to call **fit_ensemble()** after already running **fit()**. **fit()** both optimizes the machine learning models and builds an ensemble out of them. To disable ensembling when running **fit()** (with parallel instances for example) setÂ ensemble_size to 0. Then **fit_ensemble()** would be needed once all models have been built.\n",
    "\n",
    "To save fitted models, use typical [pickle procedures](https://scikit-learn.org/stable/modules/model_persistence.html#persistence-example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "\n",
    "Accuracy, sprint stats, and model details are available. \n",
    "\n",
    "Later we will run auto-sklearn in parallel. Note the number of models built here and compare it to the number built with parallelization turned on. \n",
    "\n",
    "The model details give you insight into what auto-sklearn is doing under the hood. You can see the modeling algorithm used and all the parameter settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.6973684210526315\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Sprint Stats:\n",
      "auto-sklearn results:\n",
      "  Dataset name: heart_disease\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.880000\n",
      "  Number of target algorithm runs: 24\n",
      "  Number of successful target algorithm runs: 24\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Model Details:\n",
      "{24: {'model_id': 24, 'rank': 1, 'cost': 0.12, 'ensemble_weight': 0.28, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e794449a0>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e79444b80>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e79444820>, 'sklearn_classifier': AdaBoostClassifier(algorithm='SAMME',\n",
      "                   base_estimator=DecisionTreeClassifier(max_depth=2),\n",
      "                   learning_rate=0.13167493237005792, n_estimators=56,\n",
      "                   random_state=1)}, 10: {'model_id': 10, 'rank': 2, 'cost': 0.1333333333333333, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e78d162b0>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e7944e8b0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e7944edf0>, 'sklearn_classifier': MLPClassifier(activation='tanh', alpha=0.0001363185819149026, beta_1=0.999,\n",
      "              beta_2=0.9, early_stopping=True,\n",
      "              hidden_layer_sizes=(115, 115, 115),\n",
      "              learning_rate_init=0.00018009776276177523, max_iter=32,\n",
      "              n_iter_no_change=32, random_state=1, verbose=0, warm_start=True)}, 13: {'model_id': 13, 'rank': 3, 'cost': 0.1333333333333333, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e78d165e0>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e78e71670>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e78dbbd60>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=0.4635442279519353,\n",
      "                               learning_rate=0.09809681787962342, max_iter=512,\n",
      "                               max_leaf_nodes=328, min_samples_leaf=2,\n",
      "                               n_iter_no_change=2, random_state=1,\n",
      "                               validation_fraction=None, warm_start=True)}, 4: {'model_id': 4, 'rank': 4, 'cost': 0.1466666666666666, 'ensemble_weight': 0.06, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e79608f70>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e784557c0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e75ad5100>, 'sklearn_classifier': MLPClassifier(activation='tanh', alpha=2.5550223982458062e-06, beta_1=0.999,\n",
      "              beta_2=0.9, hidden_layer_sizes=(54, 54, 54),\n",
      "              learning_rate_init=0.00027271287919467994, max_iter=256,\n",
      "              n_iter_no_change=32, random_state=1, validation_fraction=0.0,\n",
      "              verbose=0, warm_start=True)}, 9: {'model_id': 9, 'rank': 5, 'cost': 0.1466666666666666, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e78e6b9a0>, 'balancing': Balancing(random_state=1, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e75ad50a0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e75a4fdc0>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=2, min_samples_leaf=2,\n",
      "                       n_estimators=512, n_jobs=1, random_state=1,\n",
      "                       warm_start=True)}, 16: {'model_id': 16, 'rank': 6, 'cost': 0.17333333333333334, 'ensemble_weight': 0.16, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e78e23970>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e75a4ff10>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e730ccbb0>, 'sklearn_classifier': AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
      "                   learning_rate=0.046269426995092074, n_estimators=406,\n",
      "                   random_state=1)}, 15: {'model_id': 15, 'rank': 7, 'cost': 0.18666666666666665, 'ensemble_weight': 0.08, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e78461c40>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e730cc970>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e616fe220>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=15, n_estimators=512,\n",
      "                       n_jobs=1, random_state=1, warm_start=True)}, 21: {'model_id': 21, 'rank': 8, 'cost': 0.19999999999999996, 'ensemble_weight': 0.12, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e75aef670>, 'balancing': Balancing(random_state=1, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e614f64f0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e614f6970>, 'sklearn_classifier': DecisionTreeClassifier(class_weight='balanced', max_depth=22,\n",
      "                       min_samples_leaf=4, min_samples_split=20,\n",
      "                       random_state=1)}, 25: {'model_id': 25, 'rank': 9, 'cost': 0.22666666666666668, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e7318bc10>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e61382490>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e61382a90>, 'sklearn_classifier': RandomForestClassifier(bootstrap=False, criterion='entropy', max_features=928,\n",
      "                       min_samples_leaf=7, min_samples_split=8,\n",
      "                       n_estimators=512, n_jobs=1, random_state=1,\n",
      "                       warm_start=True)}, 22: {'model_id': 22, 'rank': 10, 'cost': 0.28, 'ensemble_weight': 0.06, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e615972e0>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e61570f70>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e615706d0>, 'sklearn_classifier': SVC(C=1198.7850746967626, cache_size=1943.953125, gamma=0.015219182148092949,\n",
      "    max_iter=-1.0, random_state=1, tol=0.040610448809956276)}, 20: {'model_id': 20, 'rank': 11, 'cost': 0.43999999999999995, 'ensemble_weight': 0.16, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e61487760>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e611539a0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e61153dc0>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=0.0015246021799433245,\n",
      "                               learning_rate=0.051072202871981255, max_iter=32,\n",
      "                               max_leaf_nodes=377, min_samples_leaf=100,\n",
      "                               n_iter_no_change=17, random_state=1,\n",
      "                               validation_fraction=0.2801600670702926,\n",
      "                               warm_start=True)}}\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                     predictions_hd_ohe))\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "print('Sprint Stats:')\n",
    "print(automl_hd_ohe.sprint_statistics())\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "print('Model Details:')\n",
    "print(automl_hd_ohe.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the same thing (build a model on ohe data with holdout) but this time with parallelization turned on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2022-08-11 15:22:50,090:Client-AutoML(5):heart_disease] Capping the per_run_time_limit to 29.0 to have time for a least 2 models in each process.\n",
      "[ERROR] [2022-08-11 15:23:43,524:asyncio.events] \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/utils.py\", line 799, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/client.py\", line 1246, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/client.py\", line 1276, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/comm/core.py\", line 315, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/opt/conda/lib/python3.8/asyncio/tasks.py\", line 659, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "[ERROR] [2022-08-11 15:23:43,527:asyncio.events] \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/utils.py\", line 799, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/client.py\", line 1435, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/utils.py\", line 799, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/client.py\", line 1246, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/client.py\", line 1276, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/comm/core.py\", line 315, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/opt/conda/lib/python3.8/asyncio/tasks.py\", line 659, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "CPU times: user 10.5 s, sys: 742 ms, total: 11.3 s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#build the auto-sklearn routine\n",
    "automl_hd_ohe_p = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=60,\n",
    "    per_run_time_limit=30,\n",
    "    disable_evaluator_output=False,\n",
    "    resampling_strategy='holdout',\n",
    "    resampling_strategy_arguments={'train_size': 0.67},\n",
    "    \n",
    "    #turn on parallelization\n",
    "    n_jobs=4,\n",
    "    seed=5,\n",
    ")\n",
    "\n",
    "#call it\n",
    "automl_hd_ohe_p.fit(X_hd_ohe_train, y_hd_ohe_train, \\\n",
    "                    dataset_name='heart_disease')\n",
    "\n",
    "#save the predicitons\n",
    "predictions_hd_ohe_p = automl_hd_ohe_p.predict(X_hd_ohe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.6842105263157895\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Sprint Stats:\n",
      "auto-sklearn results:\n",
      "  Dataset name: heart_disease\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.866667\n",
      "  Number of target algorithm runs: 24\n",
      "  Number of successful target algorithm runs: 22\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 2\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                     predictions_hd_ohe_p))\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "print('Sprint Stats:')\n",
    "print(automl_hd_ohe_p.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details:\n",
      "{3: {'model_id': 3, 'rank': 1, 'cost': 0.1333333333333333, 'ensemble_weight': 0.18, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e70a5dc70>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e650a92b0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e6b5f3f10>, 'sklearn_classifier': ExtraTreesClassifier(max_features=6, min_samples_split=10, n_estimators=512,\n",
      "                     n_jobs=1, random_state=5, warm_start=True)}, 13: {'model_id': 13, 'rank': 2, 'cost': 0.1333333333333333, 'ensemble_weight': 0.12, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e6bbcfd30>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e5e9161c0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e651e1670>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=0.4635442279519353,\n",
      "                               learning_rate=0.09809681787962342, max_iter=512,\n",
      "                               max_leaf_nodes=328, min_samples_leaf=2,\n",
      "                               n_iter_no_change=2, random_state=5,\n",
      "                               validation_fraction=None, warm_start=True)}, 5: {'model_id': 5, 'rank': 3, 'cost': 0.16000000000000003, 'ensemble_weight': 0.08, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e650a9d90>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e6b52f1c0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e6b788a30>, 'sklearn_classifier': RandomForestClassifier(max_features=2, min_samples_leaf=2, n_estimators=512,\n",
      "                       n_jobs=1, random_state=5, warm_start=True)}, 7: {'model_id': 7, 'rank': 4, 'cost': 0.16000000000000003, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e65151c10>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e6b788b80>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e6bad6d60>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=1, n_estimators=512,\n",
      "                       n_jobs=1, random_state=5, warm_start=True)}, 15: {'model_id': 15, 'rank': 5, 'cost': 0.16000000000000003, 'ensemble_weight': 0.06, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e6b52f2e0>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e706ac2e0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e652a6400>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=14, n_estimators=512,\n",
      "                       n_jobs=1, random_state=5, warm_start=True)}, 16: {'model_id': 16, 'rank': 6, 'cost': 0.17333333333333334, 'ensemble_weight': 0.06, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e6b7785e0>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e651bc9a0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e5e787760>, 'sklearn_classifier': AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
      "                   learning_rate=0.046269426995092074, n_estimators=406,\n",
      "                   random_state=5)}, 2: {'model_id': 2, 'rank': 7, 'cost': 0.18666666666666665, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e6b631220>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e5e787d60>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e5e7d2d30>, 'sklearn_classifier': RandomForestClassifier(max_features=4, n_estimators=512, n_jobs=1,\n",
      "                       random_state=5, warm_start=True)}, 4: {'model_id': 4, 'rank': 8, 'cost': 0.18666666666666665, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e5e982400>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e36a57f10>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e36917970>, 'sklearn_classifier': MLPClassifier(activation='tanh', alpha=2.5550223982458062e-06, beta_1=0.999,\n",
      "              beta_2=0.9, hidden_layer_sizes=(54, 54, 54),\n",
      "              learning_rate_init=0.00027271287919467994, max_iter=256,\n",
      "              n_iter_no_change=32, random_state=5, validation_fraction=0.0,\n",
      "              verbose=0, warm_start=True)}, 9: {'model_id': 9, 'rank': 9, 'cost': 0.18666666666666665, 'ensemble_weight': 0.06, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e650d4520>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e369178b0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e36811520>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=2, min_samples_leaf=2,\n",
      "                       n_estimators=512, n_jobs=1, random_state=5,\n",
      "                       warm_start=True)}, 11: {'model_id': 11, 'rank': 10, 'cost': 0.18666666666666665, 'ensemble_weight': 0.06, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e5e846610>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e36811910>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e36811be0>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=17, min_samples_leaf=7,\n",
      "                       n_estimators=512, n_jobs=1, random_state=5,\n",
      "                       warm_start=True)}, 14: {'model_id': 14, 'rank': 11, 'cost': 0.18666666666666665, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e5e871520>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e3666b190>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e3666b6a0>, 'sklearn_classifier': ExtraTreesClassifier(criterion='entropy', max_features=245, min_samples_leaf=2,\n",
      "                     min_samples_split=20, n_estimators=512, n_jobs=1,\n",
      "                     random_state=5, warm_start=True)}, 18: {'model_id': 18, 'rank': 12, 'cost': 0.24, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e36898730>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e363a0790>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e363a0b20>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=False,\n",
      "                               l2_regularization=4.821686883442146e-05,\n",
      "                               learning_rate=0.10161621495242192, max_iter=512,\n",
      "                               max_leaf_nodes=535, min_samples_leaf=10,\n",
      "                               n_iter_no_change=0, random_state=5,\n",
      "                               validation_fraction=None, warm_start=True)}, 22: {'model_id': 22, 'rank': 13, 'cost': 0.28, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e36732e80>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e6b6193a0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e6b619dc0>, 'sklearn_classifier': SVC(C=1198.7850746967626, cache_size=1965.2760416666667,\n",
      "    gamma=0.015219182148092949, max_iter=-1.0, random_state=5,\n",
      "    tol=0.040610448809956276)}, 19: {'model_id': 19, 'rank': 14, 'cost': 0.31999999999999995, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e365316d0>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e35ec5550>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e35ec5a30>, 'sklearn_classifier': KNeighborsClassifier(n_neighbors=1, p=1)}, 20: {'model_id': 20, 'rank': 15, 'cost': 0.43999999999999995, 'ensemble_weight': 0.14, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e6b74e160>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e35e592e0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e35e595b0>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=0.0015246021799433245,\n",
      "                               learning_rate=0.051072202871981255, max_iter=32,\n",
      "                               max_leaf_nodes=377, min_samples_leaf=100,\n",
      "                               n_iter_no_change=17, random_state=5,\n",
      "                               validation_fraction=0.2801600670702926,\n",
      "                               warm_start=True)}}\n"
     ]
    }
   ],
   "source": [
    "print('Model Details:')\n",
    "print(automl_hd_ohe_p.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the breast cancer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "print(sklearn.datasets.load_breast_cancer()['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load from sklearn\n",
    "X_bc, y_bc = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "\n",
    "#build the train and test sets\n",
    "X_bc_train, X_bc_test, y_bc_train, y_bc_test = \\\n",
    "    sklearn.model_selection.train_test_split(X_bc, y_bc, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a model using holdout and parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2022-08-11 15:23:50,785:Client-AutoML(5):breast_cancer] Capping the per_run_time_limit to 29.0 to have time for a least 2 models in each process.\n",
      "[ERROR] [2022-08-11 15:24:40,859:asyncio.events] \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/utils.py\", line 799, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/client.py\", line 1246, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/client.py\", line 1276, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/comm/core.py\", line 315, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/opt/conda/lib/python3.8/asyncio/tasks.py\", line 659, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "[ERROR] [2022-08-11 15:24:40,861:asyncio.events] \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/utils.py\", line 799, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/client.py\", line 1435, in _handle_report\n",
      "    await self._reconnect()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/utils.py\", line 799, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/client.py\", line 1246, in _reconnect\n",
      "    await self._ensure_connected(timeout=timeout)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/client.py\", line 1276, in _ensure_connected\n",
      "    comm = await connect(\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/distributed/comm/core.py\", line 315, in connect\n",
      "    await asyncio.sleep(backoff)\n",
      "  File \"/opt/conda/lib/python3.8/asyncio/tasks.py\", line 659, in sleep\n",
      "    return await future\n",
      "asyncio.exceptions.CancelledError\n",
      "CPU times: user 5.09 s, sys: 658 ms, total: 5.75 s\n",
      "Wall time: 57.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#set and clear the output directorie\n",
    "# directories_bc = ['../results/tmp_bc', '../results/out_bc']\n",
    "# cleanup(directories_bc, True)\n",
    "\n",
    "#build the auto-sklearn routine\n",
    "automl_bc = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=60,\n",
    "    per_run_time_limit=30,\n",
    "    # tmp_folder=directories_bc[0],\n",
    "    # output_folder=directories_bc[1],\n",
    "    disable_evaluator_output=False,\n",
    "    # 'holdout' with 'train_size'=0.67 is the default argument setting\n",
    "    # for AutoSklearnClassifier. It is explicitly specified in this example\n",
    "    # for demonstrational purpose.\n",
    "    resampling_strategy='holdout',\n",
    "    resampling_strategy_arguments={'train_size': 0.67},\n",
    "    n_jobs=4,\n",
    "    seed=5,\n",
    "    # delete_output_folder_after_terminate=False,\n",
    "    # delete_tmp_folder_after_terminate=False,\n",
    ")\n",
    "\n",
    "#call it\n",
    "automl_bc.fit(X_bc_train, y_bc_train, dataset_name='breast_cancer')\n",
    "\n",
    "#save the predicitons\n",
    "predictions_bc = automl_bc.predict(X_bc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.951048951048951\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Sprint Stats:\n",
      "auto-sklearn results:\n",
      "  Dataset name: breast_cancer\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.985816\n",
      "  Number of target algorithm runs: 20\n",
      "  Number of successful target algorithm runs: 16\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 4\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(sklearn.metrics.accuracy_score(y_bc_test, \\\n",
    "                                     predictions_bc))\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "print('Sprint Stats:')\n",
    "print(automl_bc.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details:\n",
      "{3: {'model_id': 3, 'rank': 1, 'cost': 0.014184397163120588, 'ensemble_weight': 0.26, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e35940130>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e59b5b850>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e59b5b310>, 'sklearn_classifier': MLPClassifier(activation='tanh', alpha=0.0001363185819149026, beta_1=0.999,\n",
      "              beta_2=0.9, early_stopping=True,\n",
      "              hidden_layer_sizes=(115, 115, 115),\n",
      "              learning_rate_init=0.00018009776276177523, max_iter=32,\n",
      "              n_iter_no_change=32, random_state=5, verbose=0, warm_start=True)}, 7: {'model_id': 7, 'rank': 2, 'cost': 0.014184397163120588, 'ensemble_weight': 0.26, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e35cb86a0>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e59625c70>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e59625370>, 'sklearn_classifier': ExtraTreesClassifier(max_features=34, min_samples_leaf=3, min_samples_split=11,\n",
      "                     n_estimators=512, n_jobs=1, random_state=5,\n",
      "                     warm_start=True)}, 2: {'model_id': 2, 'rank': 3, 'cost': 0.021276595744680882, 'ensemble_weight': 0.08, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e6b2bc4c0>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e594cd460>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e59a04070>, 'sklearn_classifier': RandomForestClassifier(max_features=5, n_estimators=512, n_jobs=1,\n",
      "                       random_state=5, warm_start=True)}, 16: {'model_id': 16, 'rank': 4, 'cost': 0.021276595744680882, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e59a22f70>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e6b5f3ac0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e6b7a15e0>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=3.387912939529945e-10,\n",
      "                               learning_rate=0.30755227194768237, max_iter=128,\n",
      "                               max_leaf_nodes=60, min_samples_leaf=39,\n",
      "                               n_iter_no_change=18, random_state=5,\n",
      "                               validation_fraction=None, warm_start=True)}, 10: {'model_id': 10, 'rank': 5, 'cost': 0.028368794326241176, 'ensemble_weight': 0.08, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e70834490>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e70a0b9d0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e70a0ba90>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=4, min_samples_split=6,\n",
      "                       n_estimators=512, n_jobs=1, random_state=5,\n",
      "                       warm_start=True)}, 14: {'model_id': 14, 'rank': 6, 'cost': 0.028368794326241176, 'ensemble_weight': 0.06, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e70bb2610>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e5960dbb0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e3446c5b0>, 'sklearn_classifier': MLPClassifier(activation='tanh', alpha=2.5550223982458062e-06, beta_1=0.999,\n",
      "              beta_2=0.9, hidden_layer_sizes=(54, 54, 54),\n",
      "              learning_rate_init=0.00027271287919467994, max_iter=256,\n",
      "              n_iter_no_change=32, random_state=5, validation_fraction=0.0,\n",
      "              verbose=0, warm_start=True)}, 8: {'model_id': 8, 'rank': 7, 'cost': 0.03546099290780147, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e70c256d0>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e3446c8b0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e344565e0>, 'sklearn_classifier': RandomForestClassifier(max_features=2, min_samples_leaf=2, n_estimators=512,\n",
      "                       n_jobs=1, random_state=5, warm_start=True)}, 12: {'model_id': 12, 'rank': 8, 'cost': 0.03546099290780147, 'ensemble_weight': 0.06, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e59419160>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e344566d0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e344569a0>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=0.005326508887463406,\n",
      "                               learning_rate=0.060800813211425456, max_iter=512,\n",
      "                               max_leaf_nodes=6, min_samples_leaf=5,\n",
      "                               n_iter_no_change=5, random_state=5,\n",
      "                               validation_fraction=None, warm_start=True)}, 17: {'model_id': 17, 'rank': 9, 'cost': 0.03546099290780147, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e594408b0>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e14d1bbe0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e14cf71f0>, 'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=0.4635442279519353,\n",
      "                               learning_rate=0.09809681787962342, max_iter=512,\n",
      "                               max_leaf_nodes=328, min_samples_leaf=2,\n",
      "                               n_iter_no_change=2, random_state=5,\n",
      "                               validation_fraction=None, warm_start=True)}, 5: {'model_id': 5, 'rank': 10, 'cost': 0.04255319148936165, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e34498790>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e14cf7130>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e14af44f0>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=3, min_samples_leaf=2,\n",
      "                       n_estimators=512, n_jobs=1, random_state=5,\n",
      "                       warm_start=True)}, 9: {'model_id': 9, 'rank': 11, 'cost': 0.04255319148936165, 'ensemble_weight': 0.08, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e34199cd0>, 'balancing': Balancing(random_state=5, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e14af48b0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e149d7d60>, 'sklearn_classifier': ExtraTreesClassifier(max_features=7, min_samples_split=10, n_estimators=512,\n",
      "                     n_jobs=1, random_state=5, warm_start=True)}, 20: {'model_id': 20, 'rank': 12, 'cost': 0.09219858156028371, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f5e14cda5e0>, 'balancing': Balancing(random_state=5), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f5e14920670>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f5e14920970>, 'sklearn_classifier': PassiveAggressiveClassifier(C=0.14268277711454813, max_iter=32, random_state=5,\n",
      "                            tol=0.0002600768160857831, warm_start=True)}}\n"
     ]
    }
   ],
   "source": [
    "print('Model Details:')\n",
    "print(automl_bc.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Run and Accuracy Stats\n",
    "\n",
    "All in one place for easier comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Heart Disease---------------\n",
      " \n",
      " \n",
      "Model stats HD Holdout:\n",
      "auto-sklearn results:\n",
      "  Dataset name: heart_disease\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.880000\n",
      "  Number of target algorithm runs: 24\n",
      "  Number of successful target algorithm runs: 24\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      " \n",
      "Accuracy score HD Holdout:\n",
      "0.6973684210526315\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      "Model stats HD Holdout Parallel:\n",
      "auto-sklearn results:\n",
      "  Dataset name: heart_disease\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.866667\n",
      "  Number of target algorithm runs: 24\n",
      "  Number of successful target algorithm runs: 22\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 2\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      "Accuracy score HD Holdout Parallel:\n",
      "0.6842105263157895\n",
      " \n",
      "-----------------------------------------\n",
      " \n",
      " \n",
      " \n",
      "-----------Breast Cancer---------------\n",
      " \n",
      " \n",
      "Model stats BC Holdout Parallel:\n",
      "auto-sklearn results:\n",
      "  Dataset name: breast_cancer\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.985816\n",
      "  Number of target algorithm runs: 20\n",
      "  Number of successful target algorithm runs: 16\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 4\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      " \n",
      "Accuracy score BC Holdout Parallel:\n",
      "0.951048951048951\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------Heart Disease---------------\")\n",
    "print(' ')\n",
    "print(' ')\n",
    "\n",
    "print(\"Model stats HD Holdout:\")\n",
    "print(automl_hd_ohe.sprint_statistics())\n",
    "print(' ')\n",
    "print(\"Accuracy score HD Holdout:\")\n",
    "print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                     predictions_hd_ohe))\n",
    "\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "\n",
    "print(\"Model stats HD Holdout Parallel:\")\n",
    "print(automl_hd_ohe_p.sprint_statistics())\n",
    "print(\"Accuracy score HD Holdout Parallel:\")\n",
    "print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                     predictions_hd_ohe_p))\n",
    "\n",
    "print(' ')\n",
    "print('-----------------------------------------')\n",
    "print(' ')\n",
    "\n",
    "# #holdout parallel feat_type\n",
    "# print(\"Model stats HD Holdout Feature Type Parallel:\")\n",
    "# print(automl_hd_ft_p.sprint_statistics())\n",
    "# print(' ')\n",
    "# print(\"Accuracy score HD Holdout Feature Type Parallel:\")\n",
    "# print(sklearn.metrics.accuracy_score(y_hd_test, \\\n",
    "#                                      predictions_hd_ft_p))\n",
    "\n",
    "# print(' ')\n",
    "# print('-----------------------------------------')\n",
    "# print(' ')\n",
    "\n",
    "# #cross validation parallel\n",
    "# print(\"Model stats HD CV Parllel:\")\n",
    "# print(automl_hd_cv_p.sprint_statistics())\n",
    "# print(' ')\n",
    "# print(\"Accuracy score HD CV Parallel:\")\n",
    "# print(sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "#                                      predictions_hd_cv_p))\n",
    "\n",
    "print(' ')\n",
    "print(' ')\n",
    "\n",
    "print(\"-----------Breast Cancer---------------\")\n",
    "print(' ')\n",
    "print(' ')\n",
    "\n",
    "print(\"Model stats BC Holdout Parallel:\")\n",
    "print(automl_bc.sprint_statistics())\n",
    "print(' ')\n",
    "print(\"Accuracy score BC Holdout Parallel:\")\n",
    "print(sklearn.metrics.accuracy_score(y_bc_test, \\\n",
    "                                     predictions_bc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Ensemble to Disk\n",
    "\n",
    "In the specific case of [scikit-learn](https://scikit-learn.org/stable/modules/model_persistence.html#persistence-example), it may be better to use joblibâs replacement of pickle (dump & load), which is more efficient on objects that carry large numpy arrays internally as is often the case for fitted scikit-learn estimators, but can only pickle to the disk and not to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autosklearn_bc.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(automl_bc, 'autosklearn_bc.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Domino Stats File\n",
    "\n",
    "To keep things simple, we pick one of the hd models. Saving stats to this file [allows Domino to track and trend them in the Experiment Manager](https://support.dominodatalab.com/hc/en-us/articles/204348169-Diagnostic-statistics-with-dominostats-json) when this notebook is run as a batch or scheduled job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_acc = sklearn.metrics.accuracy_score(y_hd_ohe_test, \\\n",
    "                                        predictions_hd_ohe_p)\n",
    "bc_acc = sklearn.metrics.accuracy_score(y_bc_test, \\\n",
    "                                        predictions_bc)\n",
    "\n",
    "import json\n",
    "with open('dominostats.json', 'w') as f:\n",
    "    f.write(json.dumps( {\"HD_ACC\": hd_acc, \"BC_ACC\": bc_acc}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
